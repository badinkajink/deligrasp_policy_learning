{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from absl import app, flags, logging\n",
    "import flax\n",
    "import jax\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from octo.data.dataset import make_single_dataset\n",
    "from octo.model.components.action_heads import L1ActionHead\n",
    "from octo.model.components.tokenizers import LowdimObsTokenizer\n",
    "from octo.model.octo_model import OctoModel\n",
    "from octo.utils.jax_utils import initialize_compilation_cache\n",
    "from octo.utils.spec import ModuleSpec\n",
    "from octo.utils.train_utils import (\n",
    "    freeze_weights,\n",
    "    merge_params,\n",
    "    process_text,\n",
    "    TrainState,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(flags.FLAGS):\n",
    "  delattr(flags.FLAGS, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\willi\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\ipykernel_launcher.py']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets/\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs/octo\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "OCTO_CKPT_SMALL = \"C:/Users/willi/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58\"\n",
    "OCTO_CKPT_BASE = \"C:/Users/willi/.cache/huggingface/hub/models--rail-berkeley--octo-base-1.5/snapshots/ee3c10e8edd6ce2e8b1e8744d3c6fba4097bed48\"\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string(\"f\", \"\", \"notebook path hack.\")\n",
    "flags.DEFINE_string(\n",
    "    \"pretrained_path\",OCTO_CKPT_SMALL, \"Path to pre-trained Octo checkpoint directory.\"\n",
    ")\n",
    "flags.DEFINE_string(\"data_dir\", DATA_PATH, \"Path to finetuning dataset, in RLDS format.\")\n",
    "flags.DEFINE_string(\"save_dir\", EXP_LOG_PATH, \"Directory for saving finetuning checkpoints.\")\n",
    "flags.DEFINE_integer(\"batch_size\", 16, \"Batch size for finetuning.\")\n",
    "flags.DEFINE_bool(\n",
    "    \"freeze_transformer\",\n",
    "    True,\n",
    "    \"Whether pre-trained transformer weights should be frozen.\",\n",
    ")\n",
    "import sys\n",
    "FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbadinkajink\u001b[0m (\u001b[33mcorrelllab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\workspace\\deligrasp_policy_learning\\octo_policies\\wandb\\run-20241013_142739-gb6hixlf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/correlllab/jaf/runs/gb6hixlf' target=\"_blank\">octo_sm_dg</a></strong> to <a href='https://wandb.ai/correlllab/jaf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/correlllab/jaf' target=\"_blank\">https://wandb.ai/correlllab/jaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/correlllab/jaf/runs/gb6hixlf' target=\"_blank\">https://wandb.ai/correlllab/jaf/runs/gb6hixlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/correlllab/jaf/runs/gb6hixlf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2bd011be530>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup wandb for logging\n",
    "wandb.init(name=\"octo_sm_dg\", project=\"jaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.compilation_cache:Cache already previously initialized at C:\\Users\\willi\\.jax_compilation_cache\n",
      "c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "initialize_compilation_cache()\n",
    "# prevent tensorflow from using GPU memory since it's only used for data loading\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# load pre-trained model\n",
    "logging.info(\"Loading pre-trained model...\")\n",
    "pretrained_model = OctoModel.load_pretrained(FLAGS.pretrained_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make finetuning dataset\n",
    "# apply Gaussian normalization, load chunks of 50 actions since we'll train with action chunking\n",
    "# delete goal images in the data loader since we will train a language-conditioned-only policy\n",
    "# TODO: directly load this from raw data to make it less opaque?\n",
    "logging.info(\"Loading finetuning dataset...\")\n",
    "dataset = make_single_dataset(\n",
    "    dataset_kwargs=dict(\n",
    "        name=\"deligrasp_dataset\",\n",
    "        data_dir=FLAGS.data_dir,\n",
    "        image_obs_keys={\"primary\": \"image\", \"wrist\": \"wrist_image\"},\n",
    "        proprio_obs_key=\"state\",\n",
    "        language_key=\"language_instruction\",\n",
    "    ),\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=2,\n",
    "        action_horizon=15,\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        resize_size={\"primary\": (256, 256), \"wrist\": (128, 128)},\n",
    "    ),\n",
    "    train=True,\n",
    ")\n",
    "train_data_iter = (\n",
    "    dataset.repeat()\n",
    "    .unbatch()\n",
    "    .shuffle(100)  # can reduce this if RAM consumption too high\n",
    "    .batch(FLAGS.batch_size)\n",
    "    .iterator()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys:  dict_keys(['observation', 'task', 'action', 'dataset_name', 'action_pad_mask'])\n",
      "Observation keys:  dict_keys(['image_primary', 'image_wrist', 'proprio', 'timestep', 'pad_mask_dict', 'timestep_pad_mask', 'task_completed'])\n",
      "Task keys:  dict_keys(['language_instruction', 'pad_mask_dict'])\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.iterator()\n",
    "traj = next(iterator)\n",
    "print(\"Top-level keys: \", traj.keys())\n",
    "print(\"Observation keys: \", traj[\"observation\"].keys())\n",
    "print(\"Task keys: \", traj[\"task\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = pretrained_model.text_processor\n",
    "\n",
    "def process_batch(batch):\n",
    "    batch = process_text(batch, text_processor)\n",
    "    del batch[\"dataset_name\"]\n",
    "    return batch\n",
    "\n",
    "train_data_iter = map(process_batch, train_data_iter)\n",
    "example_batch = next(train_data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-training config and modify --> remove wrist cam, add proprio input, change action head\n",
    "# following Zhao et al. we use \"action chunks\" of length 50 and L1 loss for ALOHA\n",
    "config = pretrained_model.config\n",
    "config[\"model\"][\"heads\"][\"action\"][\"kwargs\"][\"action_dim\"] = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Prefix groups:\n",
      "WARNING:root:PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:Timestep groups:\n",
      "WARNING:root:TimestepGroup(name=obs_primary, shape=(1, 2, 256, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=obs_wrist, shape=(1, 2, 64, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=obs_task_language, shape=(1, 2, 16, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=readout_action, shape=(1, 2, 1, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Attention Mask                                                   </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> t=0   </span>┃<span style=\"font-weight: bold\"> t=0    </span>┃<span style=\"font-weight: bold\"> t=0   </span>┃<span style=\"font-weight: bold\"> t=0    </span>┃<span style=\"font-weight: bold\"> t=1   </span>┃<span style=\"font-weight: bold\"> t=1    </span>┃<span style=\"font-weight: bold\"> t=1   </span>┃<span style=\"font-weight: bold\"> t=1    </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> task_… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> obs_w… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> reado… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> obs_w… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> reado… </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> (16    </span>┃<span style=\"font-weight: bold\"> (256  </span>┃<span style=\"font-weight: bold\"> (64    </span>┃<span style=\"font-weight: bold\"> (16   </span>┃<span style=\"font-weight: bold\"> (1     </span>┃<span style=\"font-weight: bold\"> (256  </span>┃<span style=\"font-weight: bold\"> (64    </span>┃<span style=\"font-weight: bold\"> (16   </span>┃<span style=\"font-weight: bold\"> (1     </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│ task_language (16 tokens)          │ x      │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_primary (256 tokens)       │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_wrist (64 tokens)          │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_task_language (16 tokens)  │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 readout_action (1 tokens)      │        │       │        │       │ x      │       │        │       │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_primary (256 tokens)       │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_wrist (64 tokens)          │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_task_language (16 tokens)  │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 readout_action (1 tokens)      │        │       │        │       │        │       │        │       │ x      │\n",
       "└────────────────────────────────────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Attention Mask                                                   \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtask_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_w…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mreado…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_w…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mreado…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(256 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(64   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(1    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(256 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(64   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(1    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│ task_language (16 tokens)          │ x      │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_primary (256 tokens)       │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_wrist (64 tokens)          │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_task_language (16 tokens)  │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 readout_action (1 tokens)      │        │       │        │       │ x      │       │        │       │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_primary (256 tokens)       │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_wrist (64 tokens)          │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_task_language (16 tokens)  │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 readout_action (1 tokens)      │        │       │        │       │        │       │        │       │ x      │\n",
       "└────────────────────────────────────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                              OctoModule Summary                               \u001b[0m\n",
      "┌───────────────┬───────────────┬──────────────┬───────────────┬──────────────┐\n",
      "│\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1moutputs      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mparams      \u001b[0m\u001b[1m \u001b[0m│\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│               │ OctoModule    │ -            │ - obs:        │              │\n",
      "│               │               │ image_prima… │     mask:     │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ \u001b[2mbool\u001b[0m[1,2,336] │              │\n",
      "│               │               │   image_wri… │     tokens:   │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   pad_mask_… │   obs_primar… │              │\n",
      "│               │               │     image_p… │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mbool\u001b[0m[1,2,256] │              │\n",
      "│               │               │     image_w… │     tokens:   │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     proprio: │   obs_task_l… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     mask:     │              │\n",
      "│               │               │     timeste… │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     tokens:   │              │\n",
      "│               │               │   proprio:   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │   obs_wrist:  │              │\n",
      "│               │               │   task_comp… │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,15] │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │   timestep:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   timestep_… │   readout_ac… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     mask:     │              │\n",
      "│               │               │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ language_in… │     tokens:   │              │\n",
      "│               │               │     attenti… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │   task:       │              │\n",
      "│               │               │     input_i… │     mask:     │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │   pad_mask_… │     tokens:   │              │\n",
      "│               │               │     languag… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │   task_langu… │              │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[1,2]  │     mask:     │              │\n",
      "│               │               │ - train:     │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │ False        │     tokens:   │              │\n",
      "│               │               │   verbose:   │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ True         │ - action:     │              │\n",
      "│               │               │              │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ OctoTransfor… │ -            │ obs:          │ obs_primary… │\n",
      "│               │               │ image_prima… │   mask:       │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ \u001b[2mbool\u001b[0m[1,2,336] │ obs_wrist_p… │\n",
      "│               │               │   image_wri… │   tokens:     │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │ \u001b[2mfloat32\u001b[0m[1,2,… │ readout_act… │\n",
      "│               │               │   pad_mask_… │ obs_primary:  │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │     image_p… │   mask:       │ task_langua… │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mbool\u001b[0m[1,2,256] │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │     image_w… │   tokens:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mfloat32\u001b[0m[1,2,… │ \u001b[1m1,238,784 \u001b[0m   │\n",
      "│               │               │     proprio: │ obs_task_lan… │ \u001b[1;2m(5.0 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   mask:       │              │\n",
      "│               │               │     timeste… │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   tokens:     │              │\n",
      "│               │               │   proprio:   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ obs_wrist:    │              │\n",
      "│               │               │   task_comp… │   mask:       │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,15] │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │   timestep:  │   tokens:     │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   timestep_… │ readout_acti… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   mask:       │              │\n",
      "│               │               │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ language_in… │   tokens:     │              │\n",
      "│               │               │     attenti… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ task:         │              │\n",
      "│               │               │     input_i… │   mask:       │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │   pad_mask_… │   tokens:     │              │\n",
      "│               │               │     languag… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │ task_languag… │              │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[1,2]  │   mask:       │              │\n",
      "│               │               │ - train:     │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │ False        │   tokens:     │              │\n",
      "│               │               │   verbose:   │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder       │ FlaxT5Stack   │ attention_m… │ attentions:   │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ None          │              │\n",
      "│               │               │ determinist… │ cross_attent… │              │\n",
      "│               │               │ True         │ None          │              │\n",
      "│               │               │ input_ids:   │ hidden_state… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ None          │              │\n",
      "│               │               │ output_atte… │ last_hidden_… │              │\n",
      "│               │               │ False        │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ output_hidd… │ past_key_val… │              │\n",
      "│               │               │ False        │ None          │              │\n",
      "│               │               │ return_dict: │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ shared        │ Embed         │ \u001b[2mint32\u001b[0m[1,1]   │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/drop… │ Dropout       │ -            │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ determinist… │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/block │ FlaxT5BlockC… │ -            │ attentions:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │ None          │              │\n",
      "│               │               │ -            │ cross_attent… │              │\n",
      "│               │               │ attention_m… │ None          │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ hidden_state… │              │\n",
      "│               │               │   determini… │ None          │              │\n",
      "│               │               │ True         │ last_hidden_… │              │\n",
      "│               │               │   encoder_a… │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ None         │ past_key_val… │              │\n",
      "│               │               │   encoder_h… │ None          │              │\n",
      "│               │               │ None         │               │              │\n",
      "│               │               │   init_cach… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   output_at… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   output_hi… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/fina… │ FlaxT5LayerN… │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ LanguageToke… │ -            │ mask:         │ \u001b[1m109,628,544 \u001b[0m │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,16]    │ \u001b[1;2m(438.5 MB)\u001b[0m   │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,15] │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[768… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m295,296 \u001b[0m\u001b[1;2m(1.2\u001b[0m │\n",
      "│               │               │              │               │ \u001b[1;2mMB)\u001b[0m          │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ ImageTokeniz… │ -            │ mask:         │ \u001b[1m1,058,048 \u001b[0m   │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,2,256] │ \u001b[1;2m(4.2 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,15] │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[512… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m196,992 \u001b[0m     │\n",
      "│               │               │              │               │ \u001b[1;2m(788.0 KB)\u001b[0m   │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ ImageTokeniz… │ -            │ mask:         │ \u001b[1m1,058,048 \u001b[0m   │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,2,64]  │ \u001b[1;2m(4.2 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,15] │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[512… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m196,992 \u001b[0m     │\n",
      "│               │               │              │               │ \u001b[1;2m(788.0 KB)\u001b[0m   │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ BlockTransfo… │ - -          │ - -           │ \u001b[1m21,294,336 \u001b[0m  │\n",
      "│               │               │ attention_r… │ attention_ru… │ \u001b[1;2m(85.2 MB)\u001b[0m    │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ task_langua… │ task_language │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ - -          │ - -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,25… │ \u001b[2mbool\u001b[0m[1,2,256] │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_primary  │ obs_primary   │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,64] │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_wrist    │ obs_wrist     │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,16] │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_task_la… │ obs_task_lan… │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       reado… │       readou… │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ readout_act… │ readout_acti… │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   verbose:   │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ heads_action  │ DiffusionAct… │ - obs:       │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,33… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_prima… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,25… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_task_… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,16] │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_wrist: │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,64] │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   readout_a… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task:      │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │   task_lang… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ heads_action… │ ScoreActor    │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │ \u001b[1m1,705,616 \u001b[0m   │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │ \u001b[1;2m(6.8 MB)\u001b[0m     │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m136,672,656 \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m              \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(546.7 MB)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴───────────────┴──────────────┴───────────────┴──────────────┘\n",
      "\u001b[1m                                                                               \u001b[0m\n",
      "\u001b[1m                   Total Parameters: 136,672,656 \u001b[0m\u001b[1;2m(546.7 MB)\u001b[0m\u001b[1m                    \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize weights for modified Octo model, then merge in all applicable pre-trained weights\n",
    "# new position encodings for proprio inputs & weights for new action head will remain \"from scratch\"\n",
    "logging.info(\"Updating model for new observation & action space...\")\n",
    "model = OctoModel.from_config(\n",
    "    config,\n",
    "    example_batch,\n",
    "    text_processor,\n",
    "    verbose=True,\n",
    "    dataset_statistics=dataset.dataset_statistics,\n",
    ")\n",
    "merged_params = merge_params(model.params, pretrained_model.params)\n",
    "# can perform any additional parameter surgery here...\n",
    "# ...\n",
    "model = model.replace(params=merged_params)\n",
    "del pretrained_model\n",
    "\n",
    "# create optimizer & train_state, optionally freeze keys for pre-trained transformer\n",
    "# train_state bundles parameters & optimizers\n",
    "learning_rate = optax.join_schedules(\n",
    "    [optax.linear_schedule(0, 3e-5, 100), optax.constant_schedule(3e-5)], [100]\n",
    ")\n",
    "tx = optax.adamw(learning_rate)\n",
    "frozen_keys = model.config[\"optimizer\"][\"frozen_keys\"]\n",
    "if FLAGS.freeze_transformer:\n",
    "    frozen_keys.append(\"BlockTransformer_0\")\n",
    "tx = freeze_weights(tx, model.params, frozen_keys)\n",
    "train_state = TrainState.create(\n",
    "    rng=jax.random.PRNGKey(1234),\n",
    "    model=model,\n",
    "    tx=tx,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and train step\n",
    "def loss_fn(params, batch, rng, train=True):\n",
    "    bound_module = model.module.bind({\"params\": params}, rngs={\"dropout\": rng})\n",
    "    transformer_embeddings = bound_module.octo_transformer(\n",
    "        batch[\"observation\"],\n",
    "        batch[\"task\"],\n",
    "        batch[\"observation\"][\"timestep_pad_mask\"],\n",
    "        train=train,\n",
    "    )\n",
    "    action_loss, action_metrics = bound_module.heads[\"action\"].loss(\n",
    "        transformer_embeddings,  # Action head knows to pull out the action readout_key\n",
    "        batch[\"action\"],\n",
    "        batch[\"observation\"][\"timestep_pad_mask\"],\n",
    "        batch[\"action_pad_mask\"],\n",
    "        train=train,\n",
    "    )\n",
    "    return action_loss, action_metrics\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    rng, dropout_rng = jax.random.split(state.rng)\n",
    "    (loss, info), grads = jax.value_and_grad(loss_fn, has_aux=True)(\n",
    "        state.model.params, batch, dropout_rng, train=True\n",
    "    )\n",
    "    new_state = state.apply_gradients(grads=grads, rng=rng)\n",
    "    return new_state, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Initializer expected to generate shape (448, 256) but got shape (551, 256) instead for parameter \"kernel\" in \"/heads_action/diffusion_model/reverse_network/Dense_0\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(total_steps), total\u001b[38;5;241m=\u001b[39mtotal_steps, dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_data_iter)\n\u001b[1;32m----> 9\u001b[0m     train_state, update_info \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m n_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m         update_info \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mdevice_get(update_info)\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[32], line 22\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(state, batch)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[0;32m     21\u001b[0m     rng, dropout_rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(state\u001b[38;5;241m.\u001b[39mrng)\n\u001b[1;32m---> 22\u001b[0m     (loss, info), grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads, rng\u001b[38;5;241m=\u001b[39mrng)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_state, info\n",
      "    \u001b[1;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[32], line 10\u001b[0m, in \u001b[0;36mloss_fn\u001b[1;34m(params, batch, rng, train)\u001b[0m\n\u001b[0;32m      3\u001b[0m bound_module \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbind({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: params}, rngs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: rng})\n\u001b[0;32m      4\u001b[0m transformer_embeddings \u001b[38;5;241m=\u001b[39m bound_module\u001b[38;5;241m.\u001b[39mocto_transformer(\n\u001b[0;32m      5\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_pad_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m action_loss, action_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mbound_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Action head knows to pull out the action readout_key\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestep_pad_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_pad_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action_loss, action_metrics\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mC:\\workspace\\octo\\octo\\model\\components\\action_heads.py:510\u001b[0m, in \u001b[0;36mDiffusionActionHead.loss\u001b[1;34m(self, transformer_outputs, actions, timestep_pad_mask, action_pad_mask, train)\u001b[0m\n\u001b[0;32m    507\u001b[0m std \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_hats[time])\n\u001b[0;32m    508\u001b[0m noisy_actions \u001b[38;5;241m=\u001b[39m scale \u001b[38;5;241m*\u001b[39m actions_flat[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m std \u001b[38;5;241m*\u001b[39m noise\n\u001b[1;32m--> 510\u001b[0m pred_eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoisy_actions\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# combine the timestep pad mask with the action pad mask\u001b[39;00m\n\u001b[0;32m    515\u001b[0m mask \u001b[38;5;241m=\u001b[39m timestep_pad_mask[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m&\u001b[39m action_pad_mask\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mC:\\workspace\\octo\\octo\\model\\components\\action_heads.py:463\u001b[0m, in \u001b[0;36mDiffusionActionHead.__call__\u001b[1;34m(self, transformer_outputs, time, noisy_actions, train)\u001b[0m\n\u001b[0;32m    458\u001b[0m     time \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m*\u001b[39membeddings\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    459\u001b[0m     noisy_actions \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    460\u001b[0m         (\u001b[38;5;241m*\u001b[39membeddings\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_horizon),\n\u001b[0;32m    461\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    462\u001b[0m     )\n\u001b[1;32m--> 463\u001b[0m pred_eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_eps\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mC:\\workspace\\octo\\octo\\model\\components\\diffusion.py:47\u001b[0m, in \u001b[0;36mScoreActor.__call__\u001b[1;34m(self, obs_enc, actions, time, train)\u001b[0m\n\u001b[0;32m     44\u001b[0m     obs_enc \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(obs_enc, new_shape)\n\u001b[0;32m     46\u001b[0m reverse_input \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mconcatenate([cond_enc, obs_enc, actions], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m eps_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreverse_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m eps_pred\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mC:\\workspace\\octo\\octo\\model\\components\\diffusion.py:127\u001b[0m, in \u001b[0;36mMLPResNet.__call__\u001b[1;34m(self, x, train)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: jax\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mArrayLike, train: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m jax\u001b[38;5;241m.\u001b[39mArray:\n\u001b[1;32m--> 127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks):\n\u001b[0;32m    129\u001b[0m         x \u001b[38;5;241m=\u001b[39m MLPResNetBlock(\n\u001b[0;32m    130\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim,\n\u001b[0;32m    131\u001b[0m             act\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation,\n\u001b[0;32m    132\u001b[0m             use_layer_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_layer_norm,\n\u001b[0;32m    133\u001b[0m             dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate,\n\u001b[0;32m    134\u001b[0m         )(x, train\u001b[38;5;241m=\u001b[39mtrain)\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\flax\\linen\\linear.py:235\u001b[0m, in \u001b[0;36mDense.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;129m@compact\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    The transformed input.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m   kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m      \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[0;32m    242\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_init, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype\n\u001b[0;32m    244\u001b[0m     )\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\flax\\core\\scope.py:971\u001b[0m, in \u001b[0;36mScope.param\u001b[1;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[0;32m    966\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[1;32m--> 971\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(\n\u001b[0;32m    972\u001b[0m           name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text, jnp\u001b[38;5;241m.\u001b[39mshape(abs_val), jnp\u001b[38;5;241m.\u001b[39mshape(val)\n\u001b[0;32m    973\u001b[0m       )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mScopeParamShapeError\u001b[0m: Initializer expected to generate shape (448, 256) but got shape (551, 256) instead for parameter \"kernel\" in \"/heads_action/diffusion_model/reverse_network/Dense_0\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "n_steps = 100\n",
    "total_steps = n_epochs * n_steps\n",
    "save_every_n_epochs = 10\n",
    "save_every_n_steps = save_every_n_epochs * n_steps\n",
    "logging.info(\"Starting finetuning...\")\n",
    "for i in tqdm.tqdm(range(total_steps), total=total_steps, dynamic_ncols=True):\n",
    "    batch = next(train_data_iter)\n",
    "    train_state, update_info = train_step(train_state, batch)\n",
    "    if (i + 1) % n_steps == 0:\n",
    "        update_info = jax.device_get(update_info)\n",
    "        wandb.log(\n",
    "            flax.traverse_util.flatten_dict({\"training\": update_info}, sep=\"/\"),\n",
    "            step=i,\n",
    "        )\n",
    "    if (i + 1) % save_every_n_steps == 0:\n",
    "        # save checkpoint\n",
    "        train_state.model.save_pretrained(step=i, checkpoint_path=FLAGS.save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

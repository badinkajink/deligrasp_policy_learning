{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from absl import app, flags, logging\n",
    "import flax\n",
    "import jax\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from octo.data.dataset import make_single_dataset\n",
    "from octo.model.components.action_heads import L1ActionHead, DiffusionActionHead\n",
    "from octo.model.components.tokenizers import LowdimObsTokenizer\n",
    "from octo.model.octo_model import OctoModel\n",
    "from octo.utils.jax_utils import initialize_compilation_cache\n",
    "from octo.utils.spec import ModuleSpec\n",
    "from octo.utils.train_utils import (\n",
    "    freeze_weights,\n",
    "    merge_params,\n",
    "    process_text,\n",
    "    TrainState,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.default_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(flags.FLAGS):\n",
    "  delattr(flags.FLAGS, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\willi\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\ipykernel_launcher.py']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets/\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs/octo\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "OCTO_CKPT_SMALL = \"C:/Users/willi/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58\"\n",
    "OCTO_CKPT_BASE = \"C:/Users/willi/.cache/huggingface/hub/models--rail-berkeley--octo-base-1.5/snapshots/ee3c10e8edd6ce2e8b1e8744d3c6fba4097bed48\"\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string(\"f\", \"\", \"notebook path hack.\")\n",
    "flags.DEFINE_string(\n",
    "    \"pretrained_path\",OCTO_CKPT_SMALL, \"Path to pre-trained Octo checkpoint directory.\"\n",
    ")\n",
    "flags.DEFINE_string(\"data_dir\", DATA_PATH, \"Path to finetuning dataset, in RLDS format.\")\n",
    "flags.DEFINE_string(\"save_dir\", EXP_LOG_PATH, \"Directory for saving finetuning checkpoints.\")\n",
    "flags.DEFINE_integer(\"verbosity\", 0, \"0 is info, 1 is debug. not having this flag is breaking jax\")\n",
    "flags.DEFINE_integer(\"batch_size\", 16, \"Batch size for finetuning.\")\n",
    "flags.DEFINE_bool(\n",
    "    \"freeze_transformer\",\n",
    "    True,\n",
    "    \"Whether pre-trained transformer weights should be frozen.\",\n",
    ")\n",
    "import sys\n",
    "FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbadinkajink\u001b[0m (\u001b[33mcorrelllab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\workspace\\deligrasp_policy_learning\\octo_policies\\wandb\\run-20241029_124028-hlybsxa7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/correlllab/jaf/runs/hlybsxa7' target=\"_blank\">octo_sm_dg</a></strong> to <a href='https://wandb.ai/correlllab/jaf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/correlllab/jaf' target=\"_blank\">https://wandb.ai/correlllab/jaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/correlllab/jaf/runs/hlybsxa7' target=\"_blank\">https://wandb.ai/correlllab/jaf/runs/hlybsxa7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/correlllab/jaf/runs/hlybsxa7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x230ef2eb8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup wandb for logging\n",
    "wandb.init(name=\"octo_sm_dg\", project=\"jaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized persistent compilation cache at C:\\Users\\willi/.jax_compilation_cache\n",
      "c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "initialize_compilation_cache()\n",
    "# prevent tensorflow from using GPU memory since it's only used for data loading\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# load pre-trained model\n",
    "logging.info(\"Loading pre-trained model...\")\n",
    "pretrained_model = OctoModel.load_pretrained(FLAGS.pretrained_path)\n",
    "# pretrained_model = OctoModel.load_pretrained(OCTO_CKPT_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make finetuning dataset\n",
    "# apply Gaussian normalization, load chunks of 50 actions since we'll train with action chunking\n",
    "# delete goal images in the data loader since we will train a language-conditioned-only policy\n",
    "# TODO: directly load this from raw data to make it less opaque?\n",
    "logging.info(\"Loading finetuning dataset...\")\n",
    "dataset = make_single_dataset(\n",
    "    dataset_kwargs=dict(\n",
    "        name=\"deligrasp_dataset\",\n",
    "        data_dir=FLAGS.data_dir,\n",
    "        image_obs_keys={\"primary\": \"image\", \"wrist\": \"wrist_image\"},\n",
    "        proprio_obs_key=\"state\",\n",
    "        language_key=\"language_instruction\",\n",
    "    ),\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=2,\n",
    "        action_horizon=8,\n",
    "        subsample_length=20,\n",
    "\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        resize_size={\"primary\": (256, 256), \"wrist\": (128, 128)},\n",
    "    ),\n",
    "    train=True,\n",
    ")\n",
    "train_data_iter = (\n",
    "    dataset.repeat()\n",
    "    .unbatch()\n",
    "    .shuffle(100)  # can reduce this if RAM consumption too high\n",
    "    .batch(FLAGS.batch_size)\n",
    "    .iterator()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys:  dict_keys(['observation', 'task', 'action', 'dataset_name', 'action_pad_mask'])\n",
      "Observation keys:  dict_keys(['image_primary', 'image_wrist', 'proprio', 'timestep', 'pad_mask_dict', 'timestep_pad_mask', 'task_completed'])\n",
      "Task keys:  dict_keys(['language_instruction', 'pad_mask_dict'])\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.iterator()\n",
    "traj = next(iterator)\n",
    "print(\"Top-level keys: \", traj.keys())\n",
    "print(\"Observation keys: \", traj[\"observation\"].keys())\n",
    "print(\"Task keys: \", traj[\"task\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = pretrained_model.text_processor\n",
    "\n",
    "def process_batch(batch):\n",
    "    batch = process_text(batch, text_processor)\n",
    "    del batch[\"dataset_name\"]\n",
    "    return batch\n",
    "\n",
    "train_data_iter = map(process_batch, train_data_iter)\n",
    "example_batch = next(train_data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observation', 'task', 'action', 'action_pad_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['language_instruction', 'pad_mask_dict'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['task'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['action'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_primary', 'image_wrist', 'proprio', 'timestep', 'pad_mask_dict', 'timestep_pad_mask', 'task_completed'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['observation'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['observation']['proprio'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-training config and modify --> remove wrist cam, add proprio input, change action head\n",
    "# following Zhao et al. we use \"action chunks\" of length 50 and L1 loss for ALOHA\n",
    "config = pretrained_model.config\n",
    "# config[\"model\"][\"heads\"][\"action\"][\"kwargs\"][\"action_dim\"] = 8\n",
    "# Fully override the old action head with a new one (for smaller changes, you can use update_config)\n",
    "config[\"model\"][\"heads\"][\"action\"] = ModuleSpec.create(\n",
    "    DiffusionActionHead,\n",
    "    use_map=False,\n",
    "    action_horizon=9,\n",
    "    action_dim=8,\n",
    "    readout_key=\"readout_action\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Prefix groups:\n",
      "WARNING:root:PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:Timestep groups:\n",
      "WARNING:root:TimestepGroup(name=obs_primary, shape=(1, 2, 256, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=obs_wrist, shape=(1, 2, 64, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=obs_task_language, shape=(1, 2, 16, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n",
      "WARNING:root:TimestepGroup(name=readout_action, shape=(1, 2, 1, 384), attends_to={\n",
      "    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Attention Mask                                                   </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> t=0   </span>┃<span style=\"font-weight: bold\"> t=0    </span>┃<span style=\"font-weight: bold\"> t=0   </span>┃<span style=\"font-weight: bold\"> t=0    </span>┃<span style=\"font-weight: bold\"> t=1   </span>┃<span style=\"font-weight: bold\"> t=1    </span>┃<span style=\"font-weight: bold\"> t=1   </span>┃<span style=\"font-weight: bold\"> t=1    </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> task_… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> obs_w… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> reado… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> obs_w… </span>┃<span style=\"font-weight: bold\"> obs_… </span>┃<span style=\"font-weight: bold\"> reado… </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> (16    </span>┃<span style=\"font-weight: bold\"> (256  </span>┃<span style=\"font-weight: bold\"> (64    </span>┃<span style=\"font-weight: bold\"> (16   </span>┃<span style=\"font-weight: bold\"> (1     </span>┃<span style=\"font-weight: bold\"> (256  </span>┃<span style=\"font-weight: bold\"> (64    </span>┃<span style=\"font-weight: bold\"> (16   </span>┃<span style=\"font-weight: bold\"> (1     </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                    </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃<span style=\"font-weight: bold\"> toke… </span>┃<span style=\"font-weight: bold\"> token… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│ task_language (16 tokens)          │ x      │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_primary (256 tokens)       │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_wrist (64 tokens)          │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_task_language (16 tokens)  │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 readout_action (1 tokens)      │        │       │        │       │ x      │       │        │       │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_primary (256 tokens)       │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_wrist (64 tokens)          │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_task_language (16 tokens)  │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 readout_action (1 tokens)      │        │       │        │       │        │       │        │       │ x      │\n",
       "└────────────────────────────────────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Attention Mask                                                   \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=0   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mt=1   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtask_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_w…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mreado…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_w…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mobs_…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mreado…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m                                    \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(256 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(64   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(1    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(256 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(64   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(16  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m(1    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoke…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtoken…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│ task_language (16 tokens)          │ x      │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_primary (256 tokens)       │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_wrist (64 tokens)          │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 obs_task_language (16 tokens)  │        │ x     │ x      │ x     │ x      │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=0 readout_action (1 tokens)      │        │       │        │       │ x      │       │        │       │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_primary (256 tokens)       │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_wrist (64 tokens)          │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 obs_task_language (16 tokens)  │        │       │        │       │        │ x     │ x      │ x     │ x      │\n",
       "├────────────────────────────────────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┼───────┼────────┤\n",
       "│ t=1 readout_action (1 tokens)      │        │       │        │       │        │       │        │       │ x      │\n",
       "└────────────────────────────────────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┴───────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                              OctoModule Summary                               \u001b[0m\n",
      "┌───────────────┬───────────────┬──────────────┬───────────────┬──────────────┐\n",
      "│\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1moutputs      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mparams      \u001b[0m\u001b[1m \u001b[0m│\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│               │ OctoModule    │ -            │ - obs:        │              │\n",
      "│               │               │ image_prima… │     mask:     │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ \u001b[2mbool\u001b[0m[1,2,336] │              │\n",
      "│               │               │   image_wri… │     tokens:   │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   pad_mask_… │   obs_primar… │              │\n",
      "│               │               │     image_p… │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mbool\u001b[0m[1,2,256] │              │\n",
      "│               │               │     image_w… │     tokens:   │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     proprio: │   obs_task_l… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     mask:     │              │\n",
      "│               │               │     timeste… │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     tokens:   │              │\n",
      "│               │               │   proprio:   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │   obs_wrist:  │              │\n",
      "│               │               │   task_comp… │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,8]  │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │   timestep:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   timestep_… │   readout_ac… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │     mask:     │              │\n",
      "│               │               │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ language_in… │     tokens:   │              │\n",
      "│               │               │     attenti… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │   task:       │              │\n",
      "│               │               │     input_i… │     mask:     │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │   pad_mask_… │     tokens:   │              │\n",
      "│               │               │     languag… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │   task_langu… │              │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[1,2]  │     mask:     │              │\n",
      "│               │               │ - train:     │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │ False        │     tokens:   │              │\n",
      "│               │               │   verbose:   │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ True         │ - action:     │              │\n",
      "│               │               │              │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ OctoTransfor… │ -            │ obs:          │ obs_primary… │\n",
      "│               │               │ image_prima… │   mask:       │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ \u001b[2mbool\u001b[0m[1,2,336] │ obs_wrist_p… │\n",
      "│               │               │   image_wri… │   tokens:     │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │ \u001b[2mfloat32\u001b[0m[1,2,… │ readout_act… │\n",
      "│               │               │   pad_mask_… │ obs_primary:  │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │     image_p… │   mask:       │ task_langua… │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mbool\u001b[0m[1,2,256] │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │     image_w… │   tokens:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │ \u001b[2mfloat32\u001b[0m[1,2,… │ \u001b[1m1,238,784 \u001b[0m   │\n",
      "│               │               │     proprio: │ obs_task_lan… │ \u001b[1;2m(5.0 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   mask:       │              │\n",
      "│               │               │     timeste… │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   tokens:     │              │\n",
      "│               │               │   proprio:   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ obs_wrist:    │              │\n",
      "│               │               │   task_comp… │   mask:       │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,8]  │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │   timestep:  │   tokens:     │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   timestep_… │ readout_acti… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │   mask:       │              │\n",
      "│               │               │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ language_in… │   tokens:     │              │\n",
      "│               │               │     attenti… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ task:         │              │\n",
      "│               │               │     input_i… │   mask:       │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │   pad_mask_… │   tokens:     │              │\n",
      "│               │               │     languag… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │ task_languag… │              │\n",
      "│               │               │ - \u001b[2mbool\u001b[0m[1,2]  │   mask:       │              │\n",
      "│               │               │ - train:     │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │ False        │   tokens:     │              │\n",
      "│               │               │   verbose:   │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder       │ FlaxT5Stack   │ attention_m… │ attentions:   │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ None          │              │\n",
      "│               │               │ determinist… │ cross_attent… │              │\n",
      "│               │               │ True         │ None          │              │\n",
      "│               │               │ input_ids:   │ hidden_state… │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ None          │              │\n",
      "│               │               │ output_atte… │ last_hidden_… │              │\n",
      "│               │               │ False        │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ output_hidd… │ past_key_val… │              │\n",
      "│               │               │ False        │ None          │              │\n",
      "│               │               │ return_dict: │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ shared        │ Embed         │ \u001b[2mint32\u001b[0m[1,1]   │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/drop… │ Dropout       │ -            │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ determinist… │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/block │ FlaxT5BlockC… │ -            │ attentions:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │ None          │              │\n",
      "│               │               │ -            │ cross_attent… │              │\n",
      "│               │               │ attention_m… │ None          │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,1]   │ hidden_state… │              │\n",
      "│               │               │   determini… │ None          │              │\n",
      "│               │               │ True         │ last_hidden_… │              │\n",
      "│               │               │   encoder_a… │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "│               │               │ None         │ past_key_val… │              │\n",
      "│               │               │   encoder_h… │ None          │              │\n",
      "│               │               │ None         │               │              │\n",
      "│               │               │   init_cach… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   output_at… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   output_hi… │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ encoder/fina… │ FlaxT5LayerN… │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,1,… │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ LanguageToke… │ -            │ mask:         │ \u001b[1m109,628,544 \u001b[0m │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,16]    │ \u001b[1;2m(438.5 MB)\u001b[0m   │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,8]  │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[768… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m295,296 \u001b[0m\u001b[1;2m(1.2\u001b[0m │\n",
      "│               │               │              │               │ \u001b[1;2mMB)\u001b[0m          │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ ImageTokeniz… │ -            │ mask:         │ \u001b[1m1,058,048 \u001b[0m   │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,2,256] │ \u001b[1;2m(4.2 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,8]  │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[512… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m196,992 \u001b[0m     │\n",
      "│               │               │              │               │ \u001b[1;2m(788.0 KB)\u001b[0m   │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ ImageTokeniz… │ -            │ mask:         │ \u001b[1m1,058,048 \u001b[0m   │\n",
      "│               │               │ image_prima… │ \u001b[2mbool\u001b[0m[1,2,64]  │ \u001b[1;2m(4.2 MB)\u001b[0m     │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,2… │ tokens:       │              │\n",
      "│               │               │   image_wri… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ \u001b[2muint8\u001b[0m[1,2,1… │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     image_p… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     image_w… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     proprio: │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │     timeste… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │   proprio:   │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task_comp… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,8]  │               │              │\n",
      "│               │               │   timestep:  │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,2]   │               │              │\n",
      "│               │               │   timestep_… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2]    │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ language_in… │               │              │\n",
      "│               │               │     attenti… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │     input_i… │               │              │\n",
      "│               │               │ \u001b[2mint32\u001b[0m[1,16]  │               │              │\n",
      "│               │               │   pad_mask_… │               │              │\n",
      "│               │               │     languag… │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1]      │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │ bias:        │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[384] │\n",
      "│               │               │              │               │ kernel:      │\n",
      "│               │               │              │               │ \u001b[2mfloat32\u001b[0m[512… │\n",
      "│               │               │              │               │              │\n",
      "│               │               │              │               │ \u001b[1m196,992 \u001b[0m     │\n",
      "│               │               │              │               │ \u001b[1;2m(788.0 KB)\u001b[0m   │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ octo_transfo… │ BlockTransfo… │ - -          │ - -           │ \u001b[1m21,294,336 \u001b[0m  │\n",
      "│               │               │ attention_r… │ attention_ru… │ \u001b[1;2m(85.2 MB)\u001b[0m    │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │ \u001b[2mbool\u001b[0m[1,16]    │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ task_langua… │ task_language │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "│               │               │ - -          │ - -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,25… │ \u001b[2mbool\u001b[0m[1,2,256] │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_primary  │ obs_primary   │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,64] │ \u001b[2mbool\u001b[0m[1,2,64]  │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_wrist    │ obs_wrist     │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,16] │ \u001b[2mbool\u001b[0m[1,2,16]  │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ obs_task_la… │ obs_task_lan… │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │   -          │   -           │              │\n",
      "│               │               │ attention_r… │ attention_ru… │              │\n",
      "│               │               │       obs_*: │       obs_*:  │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       reado… │       readou… │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │       task_… │       task_*: │              │\n",
      "│               │               │ <AttentionR… │ <AttentionRu… │              │\n",
      "│               │               │ other.times… │ other.timest… │              │\n",
      "│               │               │ <=           │ <=            │              │\n",
      "│               │               │ self.timest… │ self.timeste… │              │\n",
      "│               │               │     mask:    │     mask:     │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     name:    │     name:     │              │\n",
      "│               │               │ readout_act… │ readout_acti… │              │\n",
      "│               │               │     tokens:  │     tokens:   │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "│               │               │   verbose:   │               │              │\n",
      "│               │               │ True         │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ heads_action  │ DiffusionAct… │ - obs:       │ \u001b[2mfloat32\u001b[0m[1,2,… │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,33… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_prima… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,25… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_task_… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,16] │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   obs_wrist: │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,2,64] │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   readout_a… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │   task:      │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │   task_lang… │               │              │\n",
      "│               │               │     mask:    │               │              │\n",
      "│               │               │ \u001b[2mbool\u001b[0m[1,16]   │               │              │\n",
      "│               │               │     tokens:  │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,1… │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ heads_action… │ ScoreActor    │ -            │ \u001b[2mfloat32\u001b[0m[1,2,… │ \u001b[1m1,726,136 \u001b[0m   │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │ \u001b[1;2m(6.9 MB)\u001b[0m     │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │ -            │               │              │\n",
      "│               │               │ \u001b[2mfloat32\u001b[0m[1,2… │               │              │\n",
      "│               │               │ - train:     │               │              │\n",
      "│               │               │ False        │               │              │\n",
      "├───────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m136,693,176 \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m              \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(546.8 MB)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴───────────────┴──────────────┴───────────────┴──────────────┘\n",
      "\u001b[1m                                                                               \u001b[0m\n",
      "\u001b[1m                   Total Parameters: 136,693,176 \u001b[0m\u001b[1;2m(546.8 MB)\u001b[0m\u001b[1m                    \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize weights for modified Octo model, then merge in all applicable pre-trained weights\n",
    "# new position encodings for proprio inputs & weights for new action head will remain \"from scratch\"\n",
    "logging.info(\"Updating model for new observation & action space...\")\n",
    "model = OctoModel.from_config(\n",
    "    config,\n",
    "    example_batch,\n",
    "    text_processor,\n",
    "    verbose=True,\n",
    "    dataset_statistics=dataset.dataset_statistics,\n",
    ")\n",
    "merged_params = merge_params(model.params, pretrained_model.params)\n",
    "# can perform any additional parameter surgery here...\n",
    "# ...\n",
    "model = model.replace(params=merged_params)\n",
    "del pretrained_model\n",
    "\n",
    "# create optimizer & train_state, optionally freeze keys for pre-trained transformer\n",
    "# train_state bundles parameters & optimizers\n",
    "learning_rate = optax.join_schedules(\n",
    "    [optax.linear_schedule(0, 3e-5, 100), optax.constant_schedule(3e-5)], [100]\n",
    ")\n",
    "tx = optax.adamw(learning_rate)\n",
    "frozen_keys = model.config[\"optimizer\"][\"frozen_keys\"]\n",
    "if FLAGS.freeze_transformer:\n",
    "    frozen_keys.append(\"BlockTransformer_0\")\n",
    "tx = freeze_weights(tx, model.params, frozen_keys)\n",
    "train_state = TrainState.create(\n",
    "    rng=jax.random.PRNGKey(1234),\n",
    "    model=model,\n",
    "    tx=tx,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and train step\n",
    "def loss_fn(params, batch, rng, train=True):\n",
    "    bound_module = model.module.bind({\"params\": params}, rngs={\"dropout\": rng})\n",
    "    transformer_embeddings = bound_module.octo_transformer(\n",
    "        batch[\"observation\"],\n",
    "        batch[\"task\"],\n",
    "        batch[\"observation\"][\"timestep_pad_mask\"],\n",
    "        train=train,\n",
    "    )\n",
    "    action_loss, action_metrics = bound_module.heads[\"action\"].loss(\n",
    "        transformer_embeddings,  # Action head knows to pull out the action readout_key\n",
    "        batch[\"action\"],\n",
    "        batch[\"observation\"][\"timestep_pad_mask\"],\n",
    "        batch[\"action_pad_mask\"],\n",
    "        train=train,\n",
    "    )\n",
    "    return action_loss, action_metrics\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    rng, dropout_rng = jax.random.split(state.rng)\n",
    "    (loss, info), grads = jax.value_and_grad(loss_fn, has_aux=True)(\n",
    "        state.model.params, batch, dropout_rng, train=True\n",
    "    )\n",
    "    new_state = state.apply_gradients(grads=grads, rng=rng)\n",
    "    return new_state, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 604/3000 [7:48:32<27:46:41, 41.74s/it]Exception ignored in: <function _xla_gc_callback at 0x00000230BCE0A8C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\jax\\_src\\lib\\__init__.py\", line 101, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "KeyboardInterrupt: \n",
      " 20%|██        | 605/3000 [7:49:13<27:39:10, 41.57s/it]Exception ignored in: <function _xla_gc_callback at 0x00000230BCE0A8C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\jax\\_src\\lib\\__init__.py\", line 101, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "KeyboardInterrupt: \n",
      " 20%|██        | 606/3000 [7:49:54<27:31:59, 41.40s/it]Exception ignored in: <function _xla_gc_callback at 0x00000230BCE0A8C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\jax\\_src\\lib\\__init__.py\", line 101, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "KeyboardInterrupt: \n",
      " 20%|██        | 607/3000 [7:50:36<27:32:59, 41.45s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "n_steps = 100\n",
    "total_steps = n_epochs * n_steps\n",
    "save_every_n_epochs = 10\n",
    "save_every_n_steps = save_every_n_epochs * n_steps\n",
    "logging.info(\"Starting finetuning...\")\n",
    "for i in tqdm.tqdm(range(total_steps), total=total_steps, dynamic_ncols=True):\n",
    "    batch = next(train_data_iter)\n",
    "    train_state, update_info = train_step(train_state, batch)\n",
    "    if (i + 1) % n_steps == 0:\n",
    "        update_info = jax.device_get(update_info)\n",
    "        wandb.log(\n",
    "            flax.traverse_util.flatten_dict({\"training\": update_info}, sep=\"/\"),\n",
    "            step=i,\n",
    "        )\n",
    "    if (i + 1) % save_every_n_steps == 0:\n",
    "        # save checkpoint\n",
    "        train_state.model.save_pretrained(step=i, checkpoint_path=FLAGS.save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

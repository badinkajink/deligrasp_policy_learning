{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_visible_devices([], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mocto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleSpec\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeligrasp_dataset_transform\u001b[39;00m\n",
      "File \u001b[1;32mc:\\workspace\\deligrasp_policy_learning\\examples\\notebooks\\deligrasp_dataset_transform.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     r6_flat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([r6_0, r6_1], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r6_flat\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeligrasp_dataset_transform\u001b[39m(trajectory: \u001b[43mDict\u001b[49m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# every input feature is batched, ie has leading batch dimension\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     T \u001b[38;5;241m=\u001b[39m trajectory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, :\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     13\u001b[0m     R \u001b[38;5;241m=\u001b[39m mat_to_rot6d(euler_to_rmat(trajectory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "from robomimic.utils.rlds_utils import droid_dataset_transform, robomimic_transform, robomimic_dg_transform, TorchRLDSDataset\n",
    "\n",
    "from octo.data.dataset import make_dataset_from_rlds, make_interleaved_dataset, make_single_dataset\n",
    "from octo.data.utils.data_utils import combine_dataset_statistics\n",
    "from octo.utils.spec import ModuleSpec\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "from octo.utils.spec import ModuleSpec\n",
    "import deligrasp_dataset_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'robomimic.utils.rlds_utils' from 'c:\\\\workspace\\\\deligrasp_policy_learning\\\\robomimic\\\\utils\\\\rlds_utils.py'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import robomimic\n",
    "import numpy as np\n",
    "importlib.reload(robomimic.utils.rlds_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "builder = tfds.builder_from_directory(builder_dir=f\"{DATA_PATH}/{DATASET_NAMES}/1.0.0\")\n",
    "ds = tfds.load(f\"{DATASET_NAMES}\", data_dir=f\"{DATA_PATH}\", split=\"train\")\n",
    "trajectory = next(iter(next(iter(ds))['steps']))\n",
    "gripper_force = trajectory[\"action\"][7]\n",
    "\n",
    "# for i in ds:\n",
    "#     for j in i['steps']:\n",
    "#         print(j['observation']['state'][-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(robomimic.utils.rlds_utils)\n",
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "DATASET_NAMES = \"droid_100\"\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "sample_weights = [1]\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "# builder = tfds.builder_from_directory(f\"{DATA_PATH}/1.0.0\")\n",
    "# builder.info.features\n",
    "\n",
    "BASE_DATASET_KWARGS = {\n",
    "    \"name\": \"droid_100\",\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"image_obs_keys\": {\"primary\": \"exterior_image_1_left\", \"secondary\": \"exterior_image_2_left\"},\n",
    "    \"state_obs_keys\": [\"cartesian_position\", \"gripper_position\"],\n",
    "    \"language_key\": \"language_instruction\",\n",
    "    \"action_proprio_normalization_type\": \"bounds\",\n",
    "    \"action_normalization_mask\": [True] * 9 + [False],      # don't normalize final (gripper) dimension\n",
    "    \"standardize_fn\": ModuleSpec.create(\"robomimic.utils.rlds_utils:droid_dataset_transform\"),\n",
    "    # \"standardize_fn\": droid_dataset_transform,\n",
    "    # \"train\": True,\n",
    "}\n",
    "\n",
    "stats = make_dataset_from_rlds(**BASE_DATASET_KWARGS, train=True)\n",
    "# combined_dataset_statistics = combine_dataset_statistics(\n",
    "#     [make_dataset_from_rlds(**dataset_kwargs, train=True)[1] for dataset_kwargs in dataset_kwargs_list]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DLataset element_spec={'observation': {'image_primary': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'image_secondary': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'proprio': TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), 'timestep': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, 'task': {'language_instruction': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, 'action': TensorSpec(shape=(None, 11), dtype=tf.float32, name=None), 'dataset_name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>,\n",
       " {'action': {'mean': array([ 2.59525876e-07, -8.98353755e-06,  6.26606061e-06,  1.00000000e+00,\n",
       "          -3.94223480e-06,  1.17622549e-05,  3.95866209e-06,  1.00000000e+00,\n",
       "           1.83136490e-06, -1.90163068e-02,  1.45091570e-03]),\n",
       "   'std': array([4.99562520e-05, 5.33768907e-05, 1.40456337e-04, 6.31753039e-07,\n",
       "          1.29881650e-04, 1.99309536e-04, 1.29631822e-04, 5.01916190e-07,\n",
       "          2.10918428e-04, 9.86317545e-02, 1.46769136e-02]),\n",
       "   'max': array([2.18000001e-04, 1.80999996e-04, 5.54999977e-04, 1.00000000e+00,\n",
       "          1.81084406e-03, 8.15959647e-04, 1.00499974e-03, 1.00000000e+00,\n",
       "          7.24477088e-03, 1.58472396e-02, 3.24000001e-01]),\n",
       "   'min': array([-8.47999996e-04, -1.15899998e-03, -5.90799982e-03,  9.99962986e-01,\n",
       "          -1.00508367e-03, -8.40901490e-03, -1.74993707e-03,  9.99972224e-01,\n",
       "          -7.98014458e-04, -8.93669665e-01,  0.00000000e+00]),\n",
       "   'p99': array([1.38000003e-04, 1.18999997e-04, 2.74659996e-04, 1.00000000e+00,\n",
       "          3.59610822e-04, 3.92012255e-04, 3.70659999e-04, 1.00000000e+00,\n",
       "          4.66915850e-04, 0.00000000e+00, 3.67874987e-02]),\n",
       "   'p01': array([-1.49000000e-04, -1.51659996e-04, -2.42660000e-04,  9.99999881e-01,\n",
       "          -3.70678186e-04, -3.07659206e-04, -3.59659993e-04,  9.99999821e-01,\n",
       "          -4.34979251e-04, -7.07307884e-01,  0.00000000e+00]),\n",
       "   'mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False])},\n",
       "  'num_transitions': array(4435),\n",
       "  'num_trajectories': array(130),\n",
       "  'proprio': {'mean': array([ 1.01171303, -1.31224215,  1.76707673, -2.57167125, -1.41615617,\n",
       "          -0.30079302, -0.19634929, -0.54645783,  0.30237213, -2.51731133,\n",
       "          -0.02409072,  1.04337597,  0.57326198,  0.02742758,  0.4693388 ,\n",
       "           0.        ]),\n",
       "   'std': array([0.13072845, 0.23024239, 0.20063818, 0.35004225, 0.2672601 ,\n",
       "          0.46253482, 0.0659651 , 0.07391249, 0.07763904, 0.33785084,\n",
       "          0.09686311, 2.61964035, 0.34806189, 0.05344046, 1.32356787,\n",
       "          0.        ]),\n",
       "   'max': array([ 1.60398901, -0.85035598,  2.5169909 , -1.45508695, -0.76458901,\n",
       "           1.30379105,  0.079283  , -0.33920699,  0.55948699,  3.14014101,\n",
       "           0.26982599,  3.14155197,  1.01584721,  0.324     , 13.03741074,\n",
       "           0.        ]),\n",
       "   'min': array([ 0.62804401, -2.04883099,  1.17666197, -3.84334803, -2.28298497,\n",
       "          -1.63704503, -0.35382101, -0.69612801,  0.17777801, -3.1407361 ,\n",
       "          -0.52094698, -3.14156389, -0.01819494,  0.        ,  0.        ,\n",
       "           0.        ]),\n",
       "   'p99': array([ 1.39035483, -0.92975801,  2.23986258, -1.77026485, -0.85458126,\n",
       "           0.90254934,  0.00963384, -0.39100087,  0.49514204, -1.95598969,\n",
       "           0.16303398,  3.1389732 ,  1.        ,  0.324     ,  7.64366388,\n",
       "           0.        ]),\n",
       "   'p01': array([ 0.68332209, -1.84950789,  1.27181602, -3.55734823, -2.067327  ,\n",
       "          -1.38556194, -0.32398603, -0.69222353,  0.19542294, -2.96455491,\n",
       "          -0.32797139, -3.13800097,  0.030142  ,  0.        ,  0.        ,\n",
       "           0.        ])}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_single_dataset(\n",
    "    BASE_DATASET_KWARGS,\n",
    "    train=True,\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=2,\n",
    "        action_horizon=15,\n",
    "        subsample_length=20,\n",
    "        skip_unlabeled=True,            # skip all trajectories without language annotation\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        image_augment_kwargs=dict(\n",
    "        ),\n",
    "        resize_size=dict(\n",
    "            primary=[128, 128],\n",
    "            secondary=[128, 128],\n",
    "        ),\n",
    "        num_parallel_calls=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(robomimic_dg_transform, num_parallel_calls=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class test(torch.utils.data.IterableDataset):\n",
    "    \"\"\"Thin wrapper around RLDS dataset for use with PyTorch dataloaders.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rlds_dataset,\n",
    "        train=True,\n",
    "    ):\n",
    "        self._rlds_dataset = rlds_dataset\n",
    "        self._is_train = train\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample in self._rlds_dataset.as_numpy_iterator():\n",
    "            print(type(sample))\n",
    "            yield sample\n",
    "\n",
    "    def __len__(self):\n",
    "        lengths = np.array(\n",
    "            [\n",
    "                stats[\"num_transitions\"]\n",
    "                for stats in self._rlds_dataset.dataset_statistics\n",
    "            ]\n",
    "        )\n",
    "        if hasattr(self._rlds_dataset, \"sample_weights\"):\n",
    "            lengths *= np.array(self._rlds_dataset.sample_weights)\n",
    "        total_len = lengths.sum()\n",
    "        if self._is_train:\n",
    "            return int(0.95 * total_len)\n",
    "        else:\n",
    "            return int(0.05 * total_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      3\u001b[0m     pytorch_dataset,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      5\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# important to keep this to 0 so PyTorch does not mess with the parallelism\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m dli \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m----> 9\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdli\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[38;5;241m*\u001b[39m(collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[38;5;241m*\u001b[39m(collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[38;5;241m*\u001b[39m(collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[38;5;241m*\u001b[39m(collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "pytorch_dataset = test(dataset)\n",
    "train_loader = DataLoader(\n",
    "    pytorch_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,  # important to keep this to 0 so PyTorch does not mess with the parallelism\n",
    ")\n",
    "\n",
    "dli = iter(train_loader)\n",
    "batch = next(dli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader)):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menumerating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sample)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[98], line 20\u001b[0m, in \u001b[0;36mtest.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlds_dataset\u001b[38;5;241m.\u001b[39mas_numpy_iterator():\n\u001b[1;32m---> 20\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torchvision\\transforms\\functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'dict'>"
     ]
    }
   ],
   "source": [
    "for i, sample in tqdm.tqdm(enumerate(train_loader)):\n",
    "    print(\"enumerating\")\n",
    "    print(sample)\n",
    "    print(i)\n",
    "    if i == 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find trajectory length for each trajectory in dataset\n",
    "traj_lengths = []\n",
    "for traj in dataset:\n",
    "    print(traj['obs']['camera/image/varied_camera_1_left_image'].shape)\n",
    "    \n",
    "i = 0\n",
    "s = None\n",
    "for sample in pytorch_dataset:\n",
    "    print(sample)\n",
    "    s = sample\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        break\n",
    "\n",
    "# ok = s['obs'].keys()\n",
    "# ak = s['actions']\n",
    "\n",
    "# for k in ok:\n",
    "#     print(f\"type of {k}: {type(s['obs'][k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robomimic.scripts.config_gen.helper import *\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robomimic.scripts.config_gen.helper import *\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "#############################################################################\n",
    "# *************** Replace with your paths/config information ****************\n",
    "\n",
    "# Note: Assumes naming of dataset in \"datasets\" for the full DROID dataset is\n",
    "# droid\n",
    "\n",
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets/deligrasp_dataset_scaled\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "EXP_NAMES = OrderedDict(\n",
    "    [\n",
    "        # Note: you can add co-training dataset here appending\n",
    "        # a new dataset to \"datasets\" and adjusting \"sample_weights\"\n",
    "        # accordingly\n",
    "        (\"droid\", {\"datasets\": [\"droid\"],\n",
    "                   \"sample_weights\": [1]})                                    \n",
    "    ])\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "def make_generator_helper(args):\n",
    "    algo_name_short = \"diffusion_policy\"\n",
    "\n",
    "    generator = get_generator(\n",
    "        algo_name=\"diffusion_policy\",\n",
    "        config_file=os.path.join(base_path, 'robomimic/exps/templates/diffusion_policy_test.json'),\n",
    "        args=args,\n",
    "        exp_log_path=EXP_LOG_PATH,\n",
    "        algo_name_short=algo_name_short,\n",
    "        pt=True,\n",
    "    )\n",
    "    if args.ckpt_mode is None:\n",
    "        args.ckpt_mode = \"off\"\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.data_format\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[\n",
    "            \"droid_rlds\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.num_epochs\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[100000],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.data_path\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[DATA_PATH],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.shuffle_buffer_size\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[500000],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.batch_size\",\n",
    "        name=\"bz\",\n",
    "        group=1212111,\n",
    "        values=[128],\n",
    "        hidename=False,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.subsample_length\",\n",
    "        name=\"subsample_length\",\n",
    "        group=7070707,\n",
    "        values=[\n",
    "            100\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.num_parallel_calls\",\n",
    "        name=\"num_parallel_calls\",\n",
    "        group=404040404,\n",
    "        values=[\n",
    "            200\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.traj_transform_threads\",\n",
    "        name=\"traj_transform_threads\",\n",
    "        group=303030303,\n",
    "        values=[\n",
    "            48\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.traj_read_threads\",\n",
    "        name=\"traj_read_threads\",\n",
    "        group=908090809,\n",
    "        values=[\n",
    "            48\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"algo.noise_samples\",\n",
    "        name=\"noise_samples\",\n",
    "        group=1010101,\n",
    "        values=[8],\n",
    "        value_names=[\"8\"]\n",
    "    )\n",
    "\n",
    "    # use ddim by default\n",
    "    generator.add_param(\n",
    "        key=\"algo.ddim.enabled\",\n",
    "        name=\"ddim\",\n",
    "        group=1001,\n",
    "        values=[\n",
    "            True,\n",
    "            # False,\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "    generator.add_param(\n",
    "        key=\"algo.ddpm.enabled\",\n",
    "        name=\"ddpm\",\n",
    "        group=1001,\n",
    "        values=[\n",
    "            False,\n",
    "            # True,\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    if args.env == \"deligrasp\":\n",
    "        generator.add_param(\n",
    "            key=\"train.data\",\n",
    "            name=\"ds\",\n",
    "            group=2,\n",
    "            values=[\n",
    "                [\n",
    "                    {\"path\": \"~/datasets/square/ph/square_ph_abs_tmp.hdf5\"}, # replace with your own path\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"square\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # update env config to use absolute action control\n",
    "        generator.add_param(\n",
    "            key=\"experiment.env_meta_update_dict\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                {\"env_kwargs\": {\"controller_configs\": {\"control_delta\": False}}}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        generator.add_param(\n",
    "            key=\"train.action_keys\",\n",
    "            name=\"ac_keys\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    \"action_dict/abs_pos\",\n",
    "                    \"action_dict/abs_rot_6d\",\n",
    "                    \"action_dict/gripper\",\n",
    "                    # \"actions\",\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"abs\",\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    elif args.env == \"droid\":\n",
    "        generator.add_param(\n",
    "            key=\"train.sample_weights\",\n",
    "            name=\"sample_weights\",\n",
    "            group=24988,\n",
    "            values=[\n",
    "                EXP_NAMES[k][\"sample_weights\"] for k in EXP_NAMES.keys()\n",
    "            ],\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.dataset_names\",\n",
    "            name=\"dataset_names\",\n",
    "            group=24988,\n",
    "            values=[\n",
    "                EXP_NAMES[k][\"datasets\"] for k in EXP_NAMES.keys()\n",
    "            ],\n",
    "            value_names=list(EXP_NAMES.keys())\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.action_keys\",\n",
    "            name=\"ac_keys\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    \"action/abs_pos\",\n",
    "                    \"action/abs_rot_6d\",\n",
    "                    \"action/gripper_position\",\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"abs\",\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.action_shapes\",\n",
    "            name=\"ac_shapes\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    (1, 3),\n",
    "                    (1, 6),\n",
    "                    (1, 1),\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"ac_shapes\",\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.image_dim\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [128, 128],\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.modalities.obs.rgb\",\n",
    "            name=\"cams\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # [\"camera/image/hand_camera_left_image\"],\n",
    "                # [\"camera/image/hand_camera_left_image\", \"camera/image/hand_camera_right_image\"],\n",
    "                [\"camera/image/varied_camera_1_left_image\", \"camera/image/varied_camera_2_left_image\"],\n",
    "                # [\n",
    "                    # \"camera/image/hand_camera_left_image\", \"camera/image/hand_camera_right_image\",\n",
    "                #     \"camera/image/varied_camera_1_left_image\", \"camera/image/varied_camera_1_right_image\",\n",
    "                #     \"camera/image/varied_camera_2_left_image\", \"camera/image/varied_camera_2_right_image\",\n",
    "                # ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                # \"wrist\",\n",
    "                # \"wrist-stereo\",\n",
    "                \"2cams\",\n",
    "                # \"3cams-stereo\",\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.obs_randomizer_class\",\n",
    "            name=\"obsrand\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # \"ColorRandomizer\", # jitter only\n",
    "                [\"ColorRandomizer\", \"CropRandomizer\"], # jitter, followed by crop\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.obs_randomizer_kwargs\",\n",
    "            name=\"obsrandargs\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # {}, # jitter only\n",
    "                [{}, {\"crop_height\": 116, \"crop_width\": 116, \"num_crops\": 1, \"pos_enc\": False}], # jitter, followed by crop\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "\n",
    "        ### CONDITIONING\n",
    "        generator.add_param(\n",
    "            key=\"train.goal_mode\",\n",
    "            name=\"goal_mode\",\n",
    "            group=24986,\n",
    "            values = [\n",
    "                # \"geom\",\n",
    "                None, # Change this to \"geom\" to do goal conditioning\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.truncated_geom_factor\",\n",
    "            name=\"truncated_geom_factor\",\n",
    "            group=5555,\n",
    "            values = [\n",
    "                0.3,\n",
    "                # 0.5\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.modalities.obs.low_dim\",\n",
    "            name=\"ldkeys\",\n",
    "            group=24986,\n",
    "            values=[\n",
    "                [\"robot_state/cartesian_position\", \"robot_state/gripper_position\"],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"proprio-lang\",\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.use_cam\",\n",
    "            name=\"\",\n",
    "            group=2498,\n",
    "            values=[\n",
    "                False,\n",
    "                # True,\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.pretrained\",\n",
    "            name=\"\",\n",
    "            group=2498,\n",
    "            values=[\n",
    "                # False,\n",
    "                True,\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_class\",\n",
    "            name=\"visenc\",\n",
    "            group=-1,\n",
    "            values=[\"VisualCore\"],\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_class\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\"ResNet50Conv\"],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.feature_dimension\",\n",
    "            name=\"visdim\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                512,\n",
    "                # None,\n",
    "                # None\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.flatten\",\n",
    "            name=\"flatten\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                True,\n",
    "                # False,\n",
    "                # False\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.fuser\",\n",
    "            name=\"fuser\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                None,\n",
    "                # \"transformer\",\n",
    "                # \"perceiver\"\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.downsample\",\n",
    "            name=\"\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                False,\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    generator.add_param(\n",
    "        key=\"train.output_dir\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[\n",
    "            \"{exp_log_path}/{env}/{mod}/{algo_name_short}\".format(\n",
    "                exp_log_path=EXP_LOG_PATH,\n",
    "                env=args.env,\n",
    "                mod=args.mod, \n",
    "                algo_name_short=algo_name_short,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return generator\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = get_argparser()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    make_generator(args, make_generator_helper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

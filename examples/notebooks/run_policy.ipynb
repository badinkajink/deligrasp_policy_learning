{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b15f2e",
   "metadata": {},
   "source": [
    "# Run a trained policy\n",
    "\n",
    "This notebook will provide examples on how to run a trained policy and visualize the rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo_85b83fc\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy\n",
    "\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427159",
   "metadata": {},
   "source": [
    "### Download policy checkpoint\n",
    "First, let's try downloading a pretrained model from our model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfdfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained checkpooint from the model zoo\n",
    "\n",
    "ckpt_path = \"lift_ph_low_dim_epoch_1000_succ_100.pth\"\n",
    "# Lift (Proficient Human)\n",
    "urllib.request.urlretrieve(\n",
    "    \"http://downloads.cs.stanford.edu/downloads/rt_benchmark/model_zoo/lift/bc_rnn/lift_ph_low_dim_epoch_1000_succ_100.pth\",\n",
    "    filename=ckpt_path\n",
    ")\n",
    "\n",
    "assert os.path.exists(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c25c6",
   "metadata": {},
   "source": [
    "### Loading trained policy\n",
    "We have a convenient function called `policy_from_checkpoint` that takes care of building the correct model from the checkpoint and load the trained weights. Of course you could also load the checkpoint manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf84aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos', 'object', 'robot0_eef_quat', 'robot0_gripper_qpos']\n",
      "using obs modality: rgb with keys: []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This config has been locked and 'transformer' is not in this config",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m TorchUtils\u001b[38;5;241m.\u001b[39mget_torch_device(try_to_use_cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# restore policy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m policy, ckpt_dict \u001b[38;5;241m=\u001b[39m \u001b[43mFileUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspace\\droid_policy_learning\\robomimic\\utils\\file_utils.py:537\u001b[0m, in \u001b[0;36mpolicy_from_checkpoint\u001b[1;34m(device, ckpt_path, ckpt_dict, verbose)\u001b[0m\n\u001b[0;32m    534\u001b[0m     device \u001b[38;5;241m=\u001b[39m TorchUtils\u001b[38;5;241m.\u001b[39mget_torch_device(try_to_use_cuda\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# create model and load weights\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43malgo_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs_key_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mac_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mac_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m model\u001b[38;5;241m.\u001b[39mdeserialize(ckpt_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    545\u001b[0m model\u001b[38;5;241m.\u001b[39mset_eval()\n",
      "File \u001b[1;32mc:\\workspace\\droid_policy_learning\\robomimic\\algo\\algo.py:77\u001b[0m, in \u001b[0;36malgo_factory\u001b[1;34m(algo_name, config, obs_key_shapes, ac_dim, device)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# use algo factory func to get algo class and kwargs from algo config\u001b[39;00m\n\u001b[0;32m     76\u001b[0m factory_func \u001b[38;5;241m=\u001b[39m algo_name_to_factory_func(algo_name)\n\u001b[1;32m---> 77\u001b[0m algo_cls, algo_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mfactory_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# create algo instance\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algo_cls(\n\u001b[0;32m     81\u001b[0m     algo_config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39malgo,\n\u001b[0;32m     82\u001b[0m     obs_config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mobservation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39malgo_kwargs\n\u001b[0;32m     88\u001b[0m )\n",
      "File \u001b[1;32mc:\\workspace\\droid_policy_learning\\robomimic\\algo\\bc.py:43\u001b[0m, in \u001b[0;36malgo_config_to_class\u001b[1;34m(algo_config)\u001b[0m\n\u001b[0;32m     40\u001b[0m vae_enabled \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m algo_config \u001b[38;5;129;01mand\u001b[39;00m algo_config\u001b[38;5;241m.\u001b[39mvae\u001b[38;5;241m.\u001b[39menabled)\n\u001b[0;32m     42\u001b[0m rnn_enabled \u001b[38;5;241m=\u001b[39m algo_config\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m---> 43\u001b[0m transformer_enabled \u001b[38;5;241m=\u001b[39m \u001b[43malgo_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gaussian_enabled:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rnn_enabled:\n",
      "File \u001b[1;32mc:\\workspace\\droid_policy_learning\\robomimic\\config\\config.py:228\u001b[0m, in \u001b[0;36mConfig.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspace\\droid_policy_learning\\robomimic\\config\\config.py:237\u001b[0m, in \u001b[0;36mConfig.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__all_locked\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__key_locked\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 237\u001b[0m          \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis config has been locked and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not in this config\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Config(__parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, __key\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Config, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(name)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This config has been locked and 'transformer' is not in this config"
     ]
    }
   ],
   "source": [
    "device = TorchUtils.get_torch_device(try_to_use_cuda=True)\n",
    "\n",
    "# restore policy\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872a3f0",
   "metadata": {},
   "source": [
    "### Creating rollout envionment\n",
    "The policy checkpoint also contains sufficient information to recreate the environment that it's trained with. Again, you may manually create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d00c2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ckpt_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create environment from saved checkpoint\u001b[39;00m\n\u001b[0;32m      2\u001b[0m env, _ \u001b[38;5;241m=\u001b[39m FileUtils\u001b[38;5;241m.\u001b[39menv_from_checkpoint(\n\u001b[1;32m----> 3\u001b[0m     ckpt_dict\u001b[38;5;241m=\u001b[39m\u001b[43mckpt_dict\u001b[49m, \n\u001b[0;32m      4\u001b[0m     render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# we won't do on-screen rendering in the notebook\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     render_offscreen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# render to RGB images for video\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ckpt_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# create environment from saved checkpoint\n",
    "env, _ = FileUtils.env_from_checkpoint(\n",
    "    ckpt_dict=ckpt_dict, \n",
    "    render=False, # we won't do on-screen rendering in the notebook\n",
    "    render_offscreen=True, # render to RGB images for video\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0e9f",
   "metadata": {},
   "source": [
    "### Define the rollout loop\n",
    "Now let's define the main rollout loop. The loop runs the policy to a target `horizon` and optionally writes the rollout to a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(policy, env, horizon, render=False, video_writer=None, video_skip=5, camera_names=None):\n",
    "    \"\"\"\n",
    "    Helper function to carry out rollouts. Supports on-screen rendering, off-screen rendering to a video, \n",
    "    and returns the rollout trajectory.\n",
    "    Args:\n",
    "        policy (instance of RolloutPolicy): policy loaded from a checkpoint\n",
    "        env (instance of EnvBase): env loaded from a checkpoint or demonstration metadata\n",
    "        horizon (int): maximum horizon for the rollout\n",
    "        render (bool): whether to render rollout on-screen\n",
    "        video_writer (imageio writer): if provided, use to write rollout to video\n",
    "        video_skip (int): how often to write video frames\n",
    "        camera_names (list): determines which camera(s) are used for rendering. Pass more than\n",
    "            one to output a video with multiple camera views concatenated horizontally.\n",
    "    Returns:\n",
    "        stats (dict): some statistics for the rollout - such as return, horizon, and task success\n",
    "    \"\"\"\n",
    "    assert isinstance(env, EnvBase)\n",
    "    assert isinstance(policy, RolloutPolicy)\n",
    "    assert not (render and (video_writer is not None))\n",
    "\n",
    "    policy.start_episode()\n",
    "    obs = env.reset()\n",
    "    state_dict = env.get_state()\n",
    "\n",
    "    # hack that is necessary for robosuite tasks for deterministic action playback\n",
    "    obs = env.reset_to(state_dict)\n",
    "\n",
    "    results = {}\n",
    "    video_count = 0  # video frame counter\n",
    "    total_reward = 0.\n",
    "    try:\n",
    "        for step_i in range(horizon):\n",
    "\n",
    "            # get action from policy\n",
    "            act = policy(ob=obs)\n",
    "\n",
    "            # play action\n",
    "            next_obs, r, done, _ = env.step(act)\n",
    "\n",
    "            # compute reward\n",
    "            total_reward += r\n",
    "            success = env.is_success()[\"task\"]\n",
    "\n",
    "            # visualization\n",
    "            if render:\n",
    "                env.render(mode=\"human\", camera_name=camera_names[0])\n",
    "            if video_writer is not None:\n",
    "                if video_count % video_skip == 0:\n",
    "                    video_img = []\n",
    "                    for cam_name in camera_names:\n",
    "                        video_img.append(env.render(mode=\"rgb_array\", height=512, width=512, camera_name=cam_name))\n",
    "                    video_img = np.concatenate(video_img, axis=1) # concatenate horizontally\n",
    "                    video_writer.append_data(video_img)\n",
    "                video_count += 1\n",
    "\n",
    "            # break if done or if success\n",
    "            if done or success:\n",
    "                break\n",
    "\n",
    "            # update for next iter\n",
    "            obs = deepcopy(next_obs)\n",
    "            state_dict = env.get_state()\n",
    "\n",
    "    except env.rollout_exceptions as e:\n",
    "        print(\"WARNING: got rollout exception {}\".format(e))\n",
    "\n",
    "    stats = dict(Return=total_reward, Horizon=(step_i + 1), Success_Rate=float(success))\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43d371",
   "metadata": {},
   "source": [
    "### Run the policy\n",
    "Now let's rollout the policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_horizon = 400\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "video_path = \"rollout.mp4\"\n",
    "video_writer = imageio.get_writer(video_path, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa67efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = rollout(\n",
    "    policy=policy, \n",
    "    env=env, \n",
    "    horizon=rollout_horizon, \n",
    "    render=False, \n",
    "    video_writer=video_writer, \n",
    "    video_skip=5, \n",
    "    camera_names=[\"agentview\"]\n",
    ")\n",
    "print(stats)\n",
    "video_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79bc19",
   "metadata": {},
   "source": [
    "### Visualize the rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97472b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

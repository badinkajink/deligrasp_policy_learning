{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "from robomimic.utils.rlds_utils import droid_dataset_transform, robomimic_transform, TorchRLDSDataset, robomimic_dg_transform, dg_dataset_transform\n",
    "\n",
    "from octo.data.dataset import make_dataset_from_rlds, make_interleaved_dataset, make_single_dataset\n",
    "from octo.data.utils.data_utils import combine_dataset_statistics\n",
    "from octo.utils.spec import ModuleSpec\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "from octo.utils.spec import ModuleSpec\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'robomimic.utils.rlds_utils' from 'c:\\\\workspace\\\\droid_policy_learning\\\\robomimic\\\\utils\\\\rlds_utils.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import robomimic\n",
    "importlib.reload(robomimic.utils.rlds_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "DATASET_NAME = \"deligrasp_dataset\"\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "sample_weights = [1]\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "# builder = tfds.builder_from_directory(f\"{DATA_PATH}/1.0.0\")\n",
    "# builder.info.features\n",
    "\n",
    "BASE_DATASET_KWARGS = {\n",
    "    \"name\": DATASET_NAME,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"image_obs_keys\": {\"primary\": \"image\", \"secondary\": \"wrist_image\"},\n",
    "    \"state_obs_keys\": [\"cartesian_position\", \"gripper_position\", \"applied_force\", \"contact_force\"],\n",
    "    # \"state_obs_keys\": [\"state\"], # this makes [\"observation\"]['proprio'].shape len 16\n",
    "    \"language_key\": \"language_instruction\",\n",
    "    \"norm_skip_keys\":  [\"proprio\"],\n",
    "    \"action_proprio_normalization_type\": \"bounds\",\n",
    "    \"absolute_action_mask\": [False] * 11,                    # droid_dataset_transform uses absolute actions\n",
    "    \"action_normalization_mask\": [False] * 11,      # don't normalize final (gripper) dimension\n",
    "    \"standardize_fn\": dg_dataset_transform,\n",
    "}\n",
    "\n",
    "\n",
    "stats = make_dataset_from_rlds(**BASE_DATASET_KWARGS, train=True)\n",
    "# combined_dataset_statistics = combine_dataset_statistics(\n",
    "#     [make_dataset_from_rlds(**dataset_kwargs, train=True)[1] for dataset_kwargs in dataset_kwargs_list]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_single_dataset(\n",
    "    BASE_DATASET_KWARGS,\n",
    "    train=True,\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=2,\n",
    "        future_action_window_size=15,\n",
    "        subsample_length=50,\n",
    "        skip_unlabeled=True,            # skip all trajectories without language annotation\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        image_augment_kwargs=dict(\n",
    "        ),\n",
    "        resize_size=dict(\n",
    "            primary=[128, 128],\n",
    "            secondary=[128, 128],\n",
    "        ),\n",
    "        num_parallel_calls=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DLataset element_spec={'observation': {'image_primary': TensorSpec(shape=(None, 2, 128, 128, None), dtype=tf.uint8, name=None), 'image_secondary': TensorSpec(shape=(None, 2, 128, 128, None), dtype=tf.uint8, name=None), 'proprio': TensorSpec(shape=(None, 2, 9), dtype=tf.float32, name=None), 'timestep': TensorSpec(shape=(None, 2), dtype=tf.int32, name=None), 'pad_mask_dict': {'image_primary': TensorSpec(shape=(None, 2), dtype=tf.bool, name=None), 'image_secondary': TensorSpec(shape=(None, 2), dtype=tf.bool, name=None), 'proprio': TensorSpec(shape=(None, 2), dtype=tf.bool, name=None), 'timestep': TensorSpec(shape=(None, 2), dtype=tf.bool, name=None)}, 'pad_mask': TensorSpec(shape=(None, 2), dtype=tf.bool, name=None)}, 'task': {'language_instruction': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'pad_mask_dict': {'language_instruction': TensorSpec(shape=(None,), dtype=tf.bool, name=None)}}, 'action': TensorSpec(shape=(None, 17, 11), dtype=tf.float32, name=None), 'dataset_name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observation', 'task', 'action', 'dataset_name'])\n",
      "dict_keys(['image_primary', 'image_secondary', 'proprio', 'timestep', 'pad_mask_dict', 'pad_mask'])\n",
      "(None, 2, 9)\n",
      "dict_keys(['language_instruction', 'pad_mask_dict'])\n",
      "(None, 17, 11)\n",
      "Tensor(\"args_0:0\", shape=(None, 17, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "def dg_transform(trajectory: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    print(trajectory.keys())\n",
    "    print(trajectory[\"observation\"].keys())\n",
    "    print(trajectory[\"observation\"]['proprio'].shape)\n",
    "    print(trajectory[\"task\"].keys())\n",
    "    print(trajectory[\"action\"].shape)\n",
    "    print(trajectory[\"action\"])\n",
    "    return {\n",
    "        \"obs\": {\n",
    "            \"camera/image/varied_camera_1_left_image\": \n",
    "                tf.cast(trajectory[\"observation\"][\"image_primary\"], tf.float32) / 255.,\n",
    "            \"camera/image/varied_camera_2_left_image\": \n",
    "                tf.cast(trajectory[\"observation\"][\"image_secondary\"], tf.float32) / 255.,\n",
    "            \"raw_language\": trajectory[\"task\"][\"language_instruction\"],\n",
    "            \"robot_state/cartesian_position\": trajectory[\"observation\"][\"proprio\"][..., :6],\n",
    "            \"robot_state/gripper_position\": trajectory[\"observation\"][\"proprio\"][..., -3:-2],\n",
    "            \"robot_state/applied_force\": trajectory[\"observation\"][\"proprio\"][..., -2:-1],\n",
    "            \"robot_state/contact_force\": trajectory[\"observation\"][\"proprio\"][..., -1:],\n",
    "            \"pad_mask\": trajectory[\"observation\"][\"pad_mask\"][..., None],\n",
    "        },\n",
    "        \"actions\": trajectory[\"action\"][1:],\n",
    "    }\n",
    "\n",
    "test = dataset.map(dg_transform, num_parallel_calls=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(robomimic_dg_transform, num_parallel_calls=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.IterableDataset):\n",
    "    \"\"\"Thin wrapper around RLDS dataset for use with PyTorch dataloaders.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rlds_dataset,\n",
    "        train=True,\n",
    "    ):\n",
    "        self._rlds_dataset = rlds_dataset\n",
    "        self._is_train = train\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample in self._rlds_dataset.as_numpy_iterator():\n",
    "            rl = sample['obs']['raw_language']\n",
    "            sample['obs']['raw_language'] = rl.tolist()\n",
    "            yield sample\n",
    "\n",
    "    def __len__(self):\n",
    "        lengths = np.array(\n",
    "            [\n",
    "                stats[\"num_transitions\"]\n",
    "                for stats in self._rlds_dataset.dataset_statistics\n",
    "            ]\n",
    "        )\n",
    "        if hasattr(self._rlds_dataset, \"sample_weights\"):\n",
    "            lengths *= np.array(self._rlds_dataset.sample_weights)\n",
    "        total_len = lengths.sum()\n",
    "        if self._is_train:\n",
    "            return int(0.95 * total_len)\n",
    "        else:\n",
    "            return int(0.05 * total_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_dataset = robomimic.utils.rlds_utils.TorchRLDSDataset(dataset)\n",
    "pytorch_dataset = TestDataset(dataset)\n",
    "train_loader = DataLoader(\n",
    "    pytorch_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,  # important to keep this to 0 so PyTorch does not mess with the parallelism\n",
    ")\n",
    "\n",
    "# for i, sample in tqdm.tqdm(enumerate(train_loader)):\n",
    "#     if i == 5000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of camera/image/varied_camera_1_left_image: <class 'numpy.ndarray'>\n",
      "type of camera/image/varied_camera_2_left_image: <class 'numpy.ndarray'>\n",
      "type of raw_language: <class 'list'>\n",
      "type of robot_state/cartesian_position: <class 'numpy.ndarray'>\n",
      "type of robot_state/gripper_position: <class 'numpy.ndarray'>\n",
      "type of robot_state/applied_force: <class 'numpy.ndarray'>\n",
      "type of robot_state/contact_force: <class 'numpy.ndarray'>\n",
      "type of pad_mask: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# find trajectory length for each trajectory in dataset\n",
    "# traj_lengths = []\n",
    "# for traj in dataset:\n",
    "#     print(traj['obs']['camera/image/varied_camera_1_left_image'].shape)\n",
    "    \n",
    "i = 0\n",
    "s = None\n",
    "for sample in pytorch_dataset:\n",
    "    # print(sample)\n",
    "    s = sample\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        break\n",
    "\n",
    "ok = s['obs'].keys()\n",
    "ak = s['actions']\n",
    "\n",
    "for k in ok:\n",
    "    print(f\"type of {k}: {type(s['obs'][k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of camera/image/varied_camera_1_left_image: (50, 2, 128, 128, 3)\n",
      "shape of camera/image/varied_camera_2_left_image: (50, 2, 128, 128, 3)\n",
      "shape of raw_language: (50,)\n",
      "shape of robot_state/cartesian_position: (50, 2, 6)\n",
      "shape of robot_state/gripper_position: (50, 2, 1)\n",
      "shape of robot_state/applied_force: (50, 2, 1)\n",
      "shape of robot_state/contact_force: (50, 2, 1)\n",
      "shape of pad_mask: (50, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for k in ok:\n",
    "    kk = np.array(s['obs'][k])\n",
    "    print(f\"shape of {k}: {kk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 17, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robomimic.scripts.config_gen.helper import *\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robomimic.scripts.config_gen.helper import *\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "#############################################################################\n",
    "# *************** Replace with your paths/config information ****************\n",
    "\n",
    "# Note: Assumes naming of dataset in \"datasets\" for the full DROID dataset is\n",
    "# droid\n",
    "\n",
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets/deligrasp_dataset_scaled\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "EXP_NAMES = OrderedDict(\n",
    "    [\n",
    "        # Note: you can add co-training dataset here appending\n",
    "        # a new dataset to \"datasets\" and adjusting \"sample_weights\"\n",
    "        # accordingly\n",
    "        (\"droid\", {\"datasets\": [\"droid\"],\n",
    "                   \"sample_weights\": [1]})                                    \n",
    "    ])\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "def make_generator_helper(args):\n",
    "    algo_name_short = \"diffusion_policy\"\n",
    "\n",
    "    generator = get_generator(\n",
    "        algo_name=\"diffusion_policy\",\n",
    "        config_file=os.path.join(base_path, 'robomimic/exps/templates/diffusion_policy_test.json'),\n",
    "        args=args,\n",
    "        exp_log_path=EXP_LOG_PATH,\n",
    "        algo_name_short=algo_name_short,\n",
    "        pt=True,\n",
    "    )\n",
    "    if args.ckpt_mode is None:\n",
    "        args.ckpt_mode = \"off\"\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.data_format\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[\n",
    "            \"droid_rlds\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.num_epochs\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[100000],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.data_path\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[DATA_PATH],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.shuffle_buffer_size\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[500000],\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.batch_size\",\n",
    "        name=\"bz\",\n",
    "        group=1212111,\n",
    "        values=[128],\n",
    "        hidename=False,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.subsample_length\",\n",
    "        name=\"subsample_length\",\n",
    "        group=7070707,\n",
    "        values=[\n",
    "            100\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.num_parallel_calls\",\n",
    "        name=\"num_parallel_calls\",\n",
    "        group=404040404,\n",
    "        values=[\n",
    "            200\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.traj_transform_threads\",\n",
    "        name=\"traj_transform_threads\",\n",
    "        group=303030303,\n",
    "        values=[\n",
    "            48\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"train.traj_read_threads\",\n",
    "        name=\"traj_read_threads\",\n",
    "        group=908090809,\n",
    "        values=[\n",
    "            48\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    generator.add_param(\n",
    "        key=\"algo.noise_samples\",\n",
    "        name=\"noise_samples\",\n",
    "        group=1010101,\n",
    "        values=[8],\n",
    "        value_names=[\"8\"]\n",
    "    )\n",
    "\n",
    "    # use ddim by default\n",
    "    generator.add_param(\n",
    "        key=\"algo.ddim.enabled\",\n",
    "        name=\"ddim\",\n",
    "        group=1001,\n",
    "        values=[\n",
    "            True,\n",
    "            # False,\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "    generator.add_param(\n",
    "        key=\"algo.ddpm.enabled\",\n",
    "        name=\"ddpm\",\n",
    "        group=1001,\n",
    "        values=[\n",
    "            False,\n",
    "            # True,\n",
    "        ],\n",
    "        hidename=True,\n",
    "    )\n",
    "\n",
    "    if args.env == \"deligrasp\":\n",
    "        generator.add_param(\n",
    "            key=\"train.data\",\n",
    "            name=\"ds\",\n",
    "            group=2,\n",
    "            values=[\n",
    "                [\n",
    "                    {\"path\": \"~/datasets/square/ph/square_ph_abs_tmp.hdf5\"}, # replace with your own path\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"square\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # update env config to use absolute action control\n",
    "        generator.add_param(\n",
    "            key=\"experiment.env_meta_update_dict\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                {\"env_kwargs\": {\"controller_configs\": {\"control_delta\": False}}}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        generator.add_param(\n",
    "            key=\"train.action_keys\",\n",
    "            name=\"ac_keys\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    \"action_dict/abs_pos\",\n",
    "                    \"action_dict/abs_rot_6d\",\n",
    "                    \"action_dict/gripper\",\n",
    "                    # \"actions\",\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"abs\",\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    elif args.env == \"droid\":\n",
    "        generator.add_param(\n",
    "            key=\"train.sample_weights\",\n",
    "            name=\"sample_weights\",\n",
    "            group=24988,\n",
    "            values=[\n",
    "                EXP_NAMES[k][\"sample_weights\"] for k in EXP_NAMES.keys()\n",
    "            ],\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.dataset_names\",\n",
    "            name=\"dataset_names\",\n",
    "            group=24988,\n",
    "            values=[\n",
    "                EXP_NAMES[k][\"datasets\"] for k in EXP_NAMES.keys()\n",
    "            ],\n",
    "            value_names=list(EXP_NAMES.keys())\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.action_keys\",\n",
    "            name=\"ac_keys\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    \"action/abs_pos\",\n",
    "                    \"action/abs_rot_6d\",\n",
    "                    \"action/gripper_position\",\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"abs\",\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.action_shapes\",\n",
    "            name=\"ac_shapes\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [\n",
    "                    (1, 3),\n",
    "                    (1, 6),\n",
    "                    (1, 1),\n",
    "                ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"ac_shapes\",\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.image_dim\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\n",
    "                [128, 128],\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.modalities.obs.rgb\",\n",
    "            name=\"cams\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # [\"camera/image/hand_camera_left_image\"],\n",
    "                # [\"camera/image/hand_camera_left_image\", \"camera/image/hand_camera_right_image\"],\n",
    "                [\"camera/image/varied_camera_1_left_image\", \"camera/image/varied_camera_2_left_image\"],\n",
    "                # [\n",
    "                    # \"camera/image/hand_camera_left_image\", \"camera/image/hand_camera_right_image\",\n",
    "                #     \"camera/image/varied_camera_1_left_image\", \"camera/image/varied_camera_1_right_image\",\n",
    "                #     \"camera/image/varied_camera_2_left_image\", \"camera/image/varied_camera_2_right_image\",\n",
    "                # ],\n",
    "            ],\n",
    "            value_names=[\n",
    "                # \"wrist\",\n",
    "                # \"wrist-stereo\",\n",
    "                \"2cams\",\n",
    "                # \"3cams-stereo\",\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.obs_randomizer_class\",\n",
    "            name=\"obsrand\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # \"ColorRandomizer\", # jitter only\n",
    "                [\"ColorRandomizer\", \"CropRandomizer\"], # jitter, followed by crop\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.obs_randomizer_kwargs\",\n",
    "            name=\"obsrandargs\",\n",
    "            group=130,\n",
    "            values=[\n",
    "                # {}, # jitter only\n",
    "                [{}, {\"crop_height\": 116, \"crop_width\": 116, \"num_crops\": 1, \"pos_enc\": False}], # jitter, followed by crop\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "\n",
    "        ### CONDITIONING\n",
    "        generator.add_param(\n",
    "            key=\"train.goal_mode\",\n",
    "            name=\"goal_mode\",\n",
    "            group=24986,\n",
    "            values = [\n",
    "                # \"geom\",\n",
    "                None, # Change this to \"geom\" to do goal conditioning\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"train.truncated_geom_factor\",\n",
    "            name=\"truncated_geom_factor\",\n",
    "            group=5555,\n",
    "            values = [\n",
    "                0.3,\n",
    "                # 0.5\n",
    "            ]\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.modalities.obs.low_dim\",\n",
    "            name=\"ldkeys\",\n",
    "            group=24986,\n",
    "            values=[\n",
    "                [\"robot_state/cartesian_position\", \"robot_state/gripper_position\"],\n",
    "            ],\n",
    "            value_names=[\n",
    "                \"proprio-lang\",\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.use_cam\",\n",
    "            name=\"\",\n",
    "            group=2498,\n",
    "            values=[\n",
    "                False,\n",
    "                # True,\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.pretrained\",\n",
    "            name=\"\",\n",
    "            group=2498,\n",
    "            values=[\n",
    "                # False,\n",
    "                True,\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_class\",\n",
    "            name=\"visenc\",\n",
    "            group=-1,\n",
    "            values=[\"VisualCore\"],\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_class\",\n",
    "            name=\"\",\n",
    "            group=-1,\n",
    "            values=[\"ResNet50Conv\"],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.feature_dimension\",\n",
    "            name=\"visdim\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                512,\n",
    "                # None,\n",
    "                # None\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.flatten\",\n",
    "            name=\"flatten\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                True,\n",
    "                # False,\n",
    "                # False\n",
    "            ],\n",
    "            hidename=True,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.fuser\",\n",
    "            name=\"fuser\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                None,\n",
    "                # \"transformer\",\n",
    "                # \"perceiver\"\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "        generator.add_param(\n",
    "            key=\"observation.encoder.rgb.core_kwargs.backbone_kwargs.downsample\",\n",
    "            name=\"\",\n",
    "            group=1234,\n",
    "            values=[\n",
    "                False,\n",
    "            ],\n",
    "            hidename=False,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    generator.add_param(\n",
    "        key=\"train.output_dir\",\n",
    "        name=\"\",\n",
    "        group=-1,\n",
    "        values=[\n",
    "            \"{exp_log_path}/{env}/{mod}/{algo_name_short}\".format(\n",
    "                exp_log_path=EXP_LOG_PATH,\n",
    "                env=args.env,\n",
    "                mod=args.mod, \n",
    "                algo_name_short=algo_name_short,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return generator\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = get_argparser()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    make_generator(args, make_generator_helper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

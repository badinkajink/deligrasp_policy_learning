{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "from robomimic.utils.rlds_utils import droid_dataset_transform, robomimic_transform, TorchRLDSDataset\n",
    "\n",
    "from octo.data.dataset import make_dataset_from_rlds, make_interleaved_dataset\n",
    "from octo.data.utils.data_utils import combine_dataset_statistics\n",
    "from octo.utils.spec import ModuleSpec\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "from octo.utils.spec import ModuleSpec\n",
    "import deligrasp_dataset_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=int32, numpy=array([1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [1,2,3]\n",
    "r = [1,2,3,4,5,6]\n",
    "a = [1]\n",
    "b = [2]\n",
    "c = tf.concat((t,r,a,b), axis=-1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from 'c:\\\\Users\\\\willi\\\\.conda\\\\envs\\\\octo\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import robomimic\n",
    "import numpy as np\n",
    "importlib.reload(robomimic.utils.rlds_utils)\n",
    "importlib.reload(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Acceptable `dtype` for jpeg: [<class 'numpy.uint8'>] (was uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 38\u001b[0m\n\u001b[0;32m     10\u001b[0m BASE_DATASET_KWARGS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeligrasp_dataset_scaled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: DATA_PATH,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# filter_functions = [\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#     [\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#         ModuleSpec.create(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#     for d_name, f_functions in zip(DATASET_NAMES, filter_functions)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m octo_dataset \u001b[38;5;241m=\u001b[39m make_dataset_from_rlds(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mBASE_DATASET_KWARGS)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# combined_dataset_statistics = combine_dataset_statistics(\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#     [make_dataset_from_rlds(**dataset_kwargs, train=True)[1] for dataset_kwargs in dataset_kwargs_list]\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[1;32mC:\\workspace\\octo\\octo\\data\\dataset.py:382\u001b[0m, in \u001b[0;36mmake_dataset_from_rlds\u001b[1;34m(name, data_dir, train, standardize_fn, shuffle, image_obs_keys, depth_obs_keys, proprio_obs_key, language_key, action_proprio_normalization_type, dataset_statistics, force_recompute_dataset_statistics, action_normalization_mask, filter_functions, skip_norm, ignore_errors, num_parallel_reads, num_parallel_calls)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_nonzero_length\u001b[39m(traj):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mshape(traj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 382\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# load or compute dataset statistics\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_statistics, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:204\u001b[0m, in \u001b[0;36mbuilder\u001b[1;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _try_load_from_files_first(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs):\n\u001b[0;32m    203\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_only_builder\u001b[38;5;241m.\u001b[39mbuilder_from_files(\u001b[38;5;28mstr\u001b[39m(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m registered\u001b[38;5;241m.\u001b[39mDatasetNotFoundError:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\read_only_builder.py:269\u001b[0m, in \u001b[0;36mbuilder_from_files\u001b[1;34m(name, **builder_kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m   data_dirs \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mlist_data_dirs(\n\u001b[0;32m    262\u001b[0m       given_data_dir\u001b[38;5;241m=\u001b[39mbuilder_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    263\u001b[0m   )\n\u001b[0;32m    264\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m registered\u001b[38;5;241m.\u001b[39mDatasetNotFoundError(\n\u001b[0;32m    265\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find dataset files for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure the dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    266\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas been generated in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dirs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If the dataset has configs, you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    267\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmight have to specify the config name.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    268\u001b[0m   )\n\u001b[1;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\read_only_builder.py:137\u001b[0m, in \u001b[0;36mbuilder_from_directory\u001b[1;34m(builder_dir)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuilder_from_directory\u001b[39m(\n\u001b[0;32m    115\u001b[0m     builder_dir: epath\u001b[38;5;241m.\u001b[39mPathLike,\n\u001b[0;32m    116\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m dataset_builder\u001b[38;5;241m.\u001b[39mDatasetBuilder:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a `tfds.core.DatasetBuilder` from the given generated dataset path.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m  Reconstructs the `tfds.core.DatasetBuilder` without requiring the original\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    builder: `tfds.core.DatasetBuilder`, builder for dataset at the given path.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mReadOnlyBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuilder_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:288\u001b[0m, in \u001b[0;36mbuilder_init.<locals>.decorator\u001b[1;34m(function, dsbuilder, args, kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m _thread_id_to_builder_init_count[metadata\u001b[38;5;241m.\u001b[39mthread_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\read_only_builder.py:78\u001b[0m, in \u001b[0;36mReadOnlyBuilder.__init__\u001b[1;34m(self, builder_dir, info_proto)\u001b[0m\n\u001b[0;32m     75\u001b[0m builder_config \u001b[38;5;241m=\u001b[39m dataset_builder\u001b[38;5;241m.\u001b[39mBuilderConfig\u001b[38;5;241m.\u001b[39mfrom_dataset_info(info_proto)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# __init__ will call _build_data_dir, _create_builder_config,\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# _pick_version to set the data_dir, config, and version\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuilder_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuilder_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# For pickling, should come after super.__init__ which is setting that same\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# _original_state attribute.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(builder_dir\u001b[38;5;241m=\u001b[39mbuilder_dir)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:288\u001b[0m, in \u001b[0;36mbuilder_init.<locals>.decorator\u001b[1;34m(function, dsbuilder, args, kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m _thread_id_to_builder_init_count[metadata\u001b[38;5;241m.\u001b[39mthread_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1270\u001b[0m, in \u001b[0;36mFileReaderBuilder.__init__\u001b[1;34m(self, file_format, **kwargs)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;129m@tfds_logging\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder_init()\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1259\u001b[0m ):\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes an instance of FileReaderBuilder.\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \n\u001b[0;32m   1262\u001b[0m \u001b[38;5;124;03m  Callers must pass arguments as keyword arguments.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;124;03m    **kwargs: Arguments passed to `DatasetBuilder`.\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m   \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1271\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mset_file_format(file_format)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:288\u001b[0m, in \u001b[0;36mbuilder_init.<locals>.decorator\u001b[1;34m(function, dsbuilder, args, kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m _thread_id_to_builder_init_count[metadata\u001b[38;5;241m.\u001b[39mthread_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:273\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[1;34m(self, data_dir, config, version)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dir_root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_data_dir(data_dir)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m--> 273\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Use the code version (do not restore data)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39minitialize_from_bucket()\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py:620\u001b[0m, in \u001b[0;36mDatasetInfo.read_from_directory\u001b[1;34m(self, dataset_info_dir)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;66;03m# For `ReadOnlyBuilder`, reconstruct the features from the config.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m feature_lib\u001b[38;5;241m.\u001b[39mmake_config_path(dataset_info_dir)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m--> 620\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataset_info_dir\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# Restore the MetaDataDict from metadata.json if there is any\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m _metadata_filepath(dataset_info_dir)\u001b[38;5;241m.\u001b[39mexists()\n\u001b[0;32m    627\u001b[0m ):\n\u001b[0;32m    628\u001b[0m   \u001b[38;5;66;03m# If the dataset was loaded from file, self.metadata will be `None`, so\u001b[39;00m\n\u001b[0;32m    629\u001b[0m   \u001b[38;5;66;03m# we create a MetadataDict first.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:603\u001b[0m, in \u001b[0;36mFeatureConnector.from_config\u001b[1;34m(cls, root_dir)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reconstructs the FeatureConnector from the config file.\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03m  The reconstructed feature instance.\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    602\u001b[0m content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(make_config_path(root_dir)\u001b[38;5;241m.\u001b[39mread_text())\n\u001b[1;32m--> 603\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m feature\u001b[38;5;241m.\u001b[39mload_metadata(root_dir, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:422\u001b[0m, in \u001b[0;36mFeatureConnector.from_json\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m   feature_proto \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mParseDict(value, feature_pb2\u001b[38;5;241m.\u001b[39mFeature())\n\u001b[1;32m--> 422\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:572\u001b[0m, in \u001b[0;36mFeatureConnector.from_proto\u001b[1;34m(cls, feature_proto)\u001b[0m\n\u001b[0;32m    569\u001b[0m   feature_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(feature_content\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Not all feature classes accept the documentation as an argument.\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m feature\u001b[38;5;241m.\u001b[39m_set_doc(Documentation\u001b[38;5;241m.\u001b[39mfrom_proto(feature_proto))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:220\u001b[0m, in \u001b[0;36mFeaturesDict.from_json_content\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    221\u001b[0m       name: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_proto(proto)\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:221\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 221\u001b[0m       name: \u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:572\u001b[0m, in \u001b[0;36mFeatureConnector.from_proto\u001b[1;34m(cls, feature_proto)\u001b[0m\n\u001b[0;32m    569\u001b[0m   feature_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(feature_content\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Not all feature classes accept the documentation as an argument.\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m feature\u001b[38;5;241m.\u001b[39m_set_doc(Documentation\u001b[38;5;241m.\u001b[39mfrom_proto(feature_proto))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\sequence_feature.py:250\u001b[0m, in \u001b[0;36mSequence.from_json_content\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[0;32m    245\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    246\u001b[0m       feature\u001b[38;5;241m=\u001b[39mfeature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    247\u001b[0m       length\u001b[38;5;241m=\u001b[39mvalue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    248\u001b[0m   )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m--> 250\u001b[0m     feature\u001b[38;5;241m=\u001b[39m\u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    251\u001b[0m     length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m value\u001b[38;5;241m.\u001b[39mlength,\n\u001b[0;32m    252\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:572\u001b[0m, in \u001b[0;36mFeatureConnector.from_proto\u001b[1;34m(cls, feature_proto)\u001b[0m\n\u001b[0;32m    569\u001b[0m   feature_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(feature_content\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Not all feature classes accept the documentation as an argument.\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m feature\u001b[38;5;241m.\u001b[39m_set_doc(Documentation\u001b[38;5;241m.\u001b[39mfrom_proto(feature_proto))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:220\u001b[0m, in \u001b[0;36mFeaturesDict.from_json_content\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    221\u001b[0m       name: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_proto(proto)\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:221\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 221\u001b[0m       name: \u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:572\u001b[0m, in \u001b[0;36mFeatureConnector.from_proto\u001b[1;34m(cls, feature_proto)\u001b[0m\n\u001b[0;32m    569\u001b[0m   feature_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(feature_content\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Not all feature classes accept the documentation as an argument.\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m feature\u001b[38;5;241m.\u001b[39m_set_doc(Documentation\u001b[38;5;241m.\u001b[39mfrom_proto(feature_proto))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:220\u001b[0m, in \u001b[0;36mFeaturesDict.from_json_content\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    221\u001b[0m       name: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_proto(proto)\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:221\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    217\u001b[0m       k: feature_lib\u001b[38;5;241m.\u001b[39mFeatureConnector\u001b[38;5;241m.\u001b[39mfrom_json(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    218\u001b[0m   }\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m   features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 221\u001b[0m       name: \u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, proto \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    223\u001b[0m   }\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(features)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\feature.py:572\u001b[0m, in \u001b[0;36mFeatureConnector.from_proto\u001b[1;34m(cls, feature_proto)\u001b[0m\n\u001b[0;32m    569\u001b[0m   feature_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(feature_content\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Not all feature classes accept the documentation as an argument.\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m feature\u001b[38;5;241m.\u001b[39m_set_doc(Documentation\u001b[38;5;241m.\u001b[39mfrom_proto(feature_proto))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:396\u001b[0m, in \u001b[0;36mImage.from_json_content\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    389\u001b[0m   \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[0;32m    390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    391\u001b[0m       shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    392\u001b[0m       dtype\u001b[38;5;241m=\u001b[39mfeature_lib\u001b[38;5;241m.\u001b[39mdtype_from_str(value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    393\u001b[0m       encoding_format\u001b[38;5;241m=\u001b[39mvalue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding_format\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    394\u001b[0m       use_colormap\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_colormap\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    395\u001b[0m   )\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_shape_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype_from_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_format\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_colormap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_colormap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:266\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, shape, dtype, encoding_format, use_colormap, doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding_format \u001b[38;5;241m=\u001b[39m get_and_validate_encoding(encoding_format)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m get_and_validate_shape(shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding_format)\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;241m=\u001b[39m \u001b[43mget_and_validate_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoding_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_colormap \u001b[38;5;241m=\u001b[39m _get_and_validate_colormap(\n\u001b[0;32m    268\u001b[0m     use_colormap, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding_format\n\u001b[0;32m    269\u001b[0m )\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:  \u001b[38;5;66;03m# Float images encoded as 4-channels uint8\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:515\u001b[0m, in \u001b[0;36mget_and_validate_dtype\u001b[1;34m(dtype, encoding_format)\u001b[0m\n\u001b[0;32m    513\u001b[0m acceptable_dtypes \u001b[38;5;241m=\u001b[39m _ACCEPTABLE_DTYPES\u001b[38;5;241m.\u001b[39mget(encoding_format)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acceptable_dtypes \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m acceptable_dtypes:\n\u001b[1;32m--> 515\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    516\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcceptable `dtype` for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    517\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macceptable_dtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    518\u001b[0m   )\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Acceptable `dtype` for jpeg: [<class 'numpy.uint8'>] (was uint8)"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "DATASET_NAMES = \"deligrasp_dataset_scaled\"\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "sample_weights = [1]\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "# builder = tfds.builder_from_directory(f\"{DATA_PATH}/1.0.0\")\n",
    "# builder.info.features\n",
    "\n",
    "BASE_DATASET_KWARGS = {\n",
    "    \"name\": \"deligrasp_dataset_scaled\",\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"image_obs_keys\": {\"primary\": \"image\", \"secondary\": \"wrist_image\"},\n",
    "    \"proprio_obs_key\": \"state\",\n",
    "    \"language_key\": \"language_instruction\",\n",
    "    \"action_proprio_normalization_type\": \"bounds\",\n",
    "    \"action_normalization_mask\": [True] * 6 + [False] * 3,      # don't normalize final (gripper) dimension\n",
    "    # \"standardize_fn\": ModuleSpec.create(\"robomimic.utils.rlds_utils:deligrasp_dataset_transform\"),\n",
    "    # \"standardize_fn\": droid_dataset_transform,\n",
    "    \"train\": True,\n",
    "}\n",
    "\n",
    "# filter_functions = [\n",
    "#     [\n",
    "#         ModuleSpec.create(\n",
    "#             \"robomimic.utils.rlds_utils:filter_success\"\n",
    "#         )\n",
    "#     ] if d_name == \"droid\" else [] for d_name in DATASET_NAMES\n",
    "# ]\n",
    "# dataset_kwargs_list = [\n",
    "#     {\n",
    "#         \"name\": \"deligrasp_dataset_scaled\",\n",
    "#         \"filter_functions\": f_functions,\n",
    "#         **BASE_DATASET_KWARGS\n",
    "#     }\n",
    "#     for d_name, f_functions in zip(DATASET_NAMES, filter_functions)\n",
    "# ]\n",
    "octo_dataset = make_dataset_from_rlds(**BASE_DATASET_KWARGS)\n",
    "# combined_dataset_statistics = combine_dataset_statistics(\n",
    "#     [make_dataset_from_rlds(**dataset_kwargs, train=True)[1] for dataset_kwargs in dataset_kwargs_list]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'octo_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mocto_dataset\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'octo_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "octo_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

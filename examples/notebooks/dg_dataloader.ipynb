{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "from robomimic.utils.rlds_utils import droid_dataset_transform, robomimic_transform, robomimic_dg_transform, TorchRLDSDataset\n",
    "\n",
    "from octo.data.dataset import make_dataset_from_rlds, make_interleaved_dataset, make_single_dataset\n",
    "from octo.data.utils.data_utils import combine_dataset_statistics\n",
    "from octo.utils.spec import ModuleSpec\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "from octo.utils.spec import ModuleSpec\n",
    "import deligrasp_dataset_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'robomimic.utils.rlds_utils' from 'c:\\\\workspace\\\\deligrasp_policy_learning\\\\robomimic\\\\utils\\\\rlds_utils.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import robomimic\n",
    "import numpy as np\n",
    "importlib.reload(robomimic.utils.rlds_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "builder = tfds.builder_from_directory(builder_dir=f\"{DATA_PATH}/{DATASET_NAMES}/1.0.0\")\n",
    "ds = tfds.load(f\"{DATASET_NAMES}\", data_dir=f\"{DATA_PATH}\", split=\"train\")\n",
    "trajectory = next(iter(next(iter(ds))['steps']))\n",
    "gripper_force = trajectory[\"action\"][7]\n",
    "\n",
    "# for i in ds:\n",
    "#     for j in i['steps']:\n",
    "#         print(j['observation']['state'][-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(robomimic.utils.rlds_utils)\n",
    "DATA_PATH = \"C:/Users/willi/tensorflow_datasets\"    # UPDATE WITH PATH TO RLDS DATASETS\n",
    "DATASET_NAMES = \"deligrasp_dataset\"\n",
    "EXP_LOG_PATH = \"C:/workspace/deligrasp_policy_learning/logs\" # UPDATE WITH PATH TO DESIRED LOGGING DIRECTORY\n",
    "sample_weights = [1]\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "# builder = tfds.builder_from_directory(f\"{DATA_PATH}/1.0.0\")\n",
    "# builder.info.features\n",
    "\n",
    "BASE_DATASET_KWARGS = {\n",
    "    \"name\": \"deligrasp_dataset\",\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"image_obs_keys\": {\"primary\": \"image\", \"secondary\": \"wrist_image\"},\n",
    "    \"proprio_obs_key\": \"state\",\n",
    "    \"language_key\": \"language_instruction\",\n",
    "    \"action_proprio_normalization_type\": \"bounds\",\n",
    "    \"action_normalization_mask\": [True] * 9 + [False] * 2,      # don't normalize final (gripper) dimension\n",
    "    \"standardize_fn\": ModuleSpec.create(\"robomimic.utils.rlds_utils:deligrasp_dataset_transform\"),\n",
    "    # \"standardize_fn\": droid_dataset_transform,\n",
    "    # \"train\": True,\n",
    "}\n",
    "\n",
    "stats = make_dataset_from_rlds(**BASE_DATASET_KWARGS, train=True)\n",
    "# combined_dataset_statistics = combine_dataset_statistics(\n",
    "#     [make_dataset_from_rlds(**dataset_kwargs, train=True)[1] for dataset_kwargs in dataset_kwargs_list]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DLataset element_spec={'observation': {'image_primary': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'image_secondary': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'proprio': TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), 'timestep': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, 'task': {'language_instruction': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, 'action': TensorSpec(shape=(None, 11), dtype=tf.float32, name=None), 'dataset_name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>,\n",
       " {'action': {'mean': array([ 2.59525876e-07, -8.98353755e-06,  6.26606061e-06,  1.00000000e+00,\n",
       "          -3.94223480e-06,  1.17622549e-05,  3.95866209e-06,  1.00000000e+00,\n",
       "           1.83136490e-06, -1.90163068e-02,  1.45091570e-03]),\n",
       "   'std': array([4.99562520e-05, 5.33768907e-05, 1.40456337e-04, 6.31753039e-07,\n",
       "          1.29881650e-04, 1.99309536e-04, 1.29631822e-04, 5.01916190e-07,\n",
       "          2.10918428e-04, 9.86317545e-02, 1.46769136e-02]),\n",
       "   'max': array([2.18000001e-04, 1.80999996e-04, 5.54999977e-04, 1.00000000e+00,\n",
       "          1.81084406e-03, 8.15959647e-04, 1.00499974e-03, 1.00000000e+00,\n",
       "          7.24477088e-03, 1.58472396e-02, 3.24000001e-01]),\n",
       "   'min': array([-8.47999996e-04, -1.15899998e-03, -5.90799982e-03,  9.99962986e-01,\n",
       "          -1.00508367e-03, -8.40901490e-03, -1.74993707e-03,  9.99972224e-01,\n",
       "          -7.98014458e-04, -8.93669665e-01,  0.00000000e+00]),\n",
       "   'p99': array([1.38000003e-04, 1.18999997e-04, 2.74659996e-04, 1.00000000e+00,\n",
       "          3.59610822e-04, 3.92012255e-04, 3.70659999e-04, 1.00000000e+00,\n",
       "          4.66915850e-04, 0.00000000e+00, 3.67874987e-02]),\n",
       "   'p01': array([-1.49000000e-04, -1.51659996e-04, -2.42660000e-04,  9.99999881e-01,\n",
       "          -3.70678186e-04, -3.07659206e-04, -3.59659993e-04,  9.99999821e-01,\n",
       "          -4.34979251e-04, -7.07307884e-01,  0.00000000e+00]),\n",
       "   'mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False])},\n",
       "  'num_transitions': array(4435),\n",
       "  'num_trajectories': array(130),\n",
       "  'proprio': {'mean': array([ 1.01171303, -1.31224215,  1.76707673, -2.57167125, -1.41615617,\n",
       "          -0.30079302, -0.19634929, -0.54645783,  0.30237213, -2.51731133,\n",
       "          -0.02409072,  1.04337597,  0.57326198,  0.02742758,  0.4693388 ,\n",
       "           0.        ]),\n",
       "   'std': array([0.13072845, 0.23024239, 0.20063818, 0.35004225, 0.2672601 ,\n",
       "          0.46253482, 0.0659651 , 0.07391249, 0.07763904, 0.33785084,\n",
       "          0.09686311, 2.61964035, 0.34806189, 0.05344046, 1.32356787,\n",
       "          0.        ]),\n",
       "   'max': array([ 1.60398901, -0.85035598,  2.5169909 , -1.45508695, -0.76458901,\n",
       "           1.30379105,  0.079283  , -0.33920699,  0.55948699,  3.14014101,\n",
       "           0.26982599,  3.14155197,  1.01584721,  0.324     , 13.03741074,\n",
       "           0.        ]),\n",
       "   'min': array([ 0.62804401, -2.04883099,  1.17666197, -3.84334803, -2.28298497,\n",
       "          -1.63704503, -0.35382101, -0.69612801,  0.17777801, -3.1407361 ,\n",
       "          -0.52094698, -3.14156389, -0.01819494,  0.        ,  0.        ,\n",
       "           0.        ]),\n",
       "   'p99': array([ 1.39035483, -0.92975801,  2.23986258, -1.77026485, -0.85458126,\n",
       "           0.90254934,  0.00963384, -0.39100087,  0.49514204, -1.95598969,\n",
       "           0.16303398,  3.1389732 ,  1.        ,  0.324     ,  7.64366388,\n",
       "           0.        ]),\n",
       "   'p01': array([ 0.68332209, -1.84950789,  1.27181602, -3.55734823, -2.067327  ,\n",
       "          -1.38556194, -0.32398603, -0.69222353,  0.19542294, -2.96455491,\n",
       "          -0.32797139, -3.13800097,  0.030142  ,  0.        ,  0.        ,\n",
       "           0.        ])}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_single_dataset(\n",
    "    BASE_DATASET_KWARGS,\n",
    "    train=True,\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=2,\n",
    "        action_horizon=15,\n",
    "        subsample_length=60,\n",
    "        skip_unlabeled=True,            # skip all trajectories without language annotation\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        image_augment_kwargs=dict(\n",
    "        ),\n",
    "        resize_size=dict(\n",
    "            primary=[128, 128],\n",
    "            secondary=[128, 128],\n",
    "        ),\n",
    "        num_parallel_calls=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(robomimic_dg_transform, num_parallel_calls=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2, 128, 128, 3)\n",
      "(24, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(22, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(22, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(37, 2, 128, 128, 3)\n",
      "(53, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(37, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(39, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(62, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(25, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(30, 2, 128, 128, 3)\n",
      "(38, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(24, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(26, 2, 128, 128, 3)\n",
      "(26, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(38, 2, 128, 128, 3)\n",
      "(46, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(40, 2, 128, 128, 3)\n",
      "(49, 2, 128, 128, 3)\n",
      "(37, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(31, 2, 128, 128, 3)\n",
      "(44, 2, 128, 128, 3)\n",
      "(42, 2, 128, 128, 3)\n",
      "(31, 2, 128, 128, 3)\n",
      "(31, 2, 128, 128, 3)\n",
      "(29, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(31, 2, 128, 128, 3)\n",
      "(31, 2, 128, 128, 3)\n",
      "(35, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(54, 2, 128, 128, 3)\n",
      "(38, 2, 128, 128, 3)\n",
      "(35, 2, 128, 128, 3)\n",
      "(37, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(55, 2, 128, 128, 3)\n",
      "(24, 2, 128, 128, 3)\n",
      "(56, 2, 128, 128, 3)\n",
      "(48, 2, 128, 128, 3)\n",
      "(25, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(49, 2, 128, 128, 3)\n",
      "(50, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(55, 2, 128, 128, 3)\n",
      "(40, 2, 128, 128, 3)\n",
      "(43, 2, 128, 128, 3)\n",
      "(45, 2, 128, 128, 3)\n",
      "(43, 2, 128, 128, 3)\n",
      "(25, 2, 128, 128, 3)\n",
      "(27, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(33, 2, 128, 128, 3)\n",
      "(38, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(22, 2, 128, 128, 3)\n",
      "(50, 2, 128, 128, 3)\n",
      "(43, 2, 128, 128, 3)\n",
      "(37, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(24, 2, 128, 128, 3)\n",
      "(28, 2, 128, 128, 3)\n",
      "(39, 2, 128, 128, 3)\n",
      "(52, 2, 128, 128, 3)\n",
      "(46, 2, 128, 128, 3)\n",
      "(66, 2, 128, 128, 3)\n",
      "(29, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(35, 2, 128, 128, 3)\n",
      "(43, 2, 128, 128, 3)\n",
      "(26, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(29, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(30, 2, 128, 128, 3)\n",
      "(34, 2, 128, 128, 3)\n",
      "(30, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(23, 2, 128, 128, 3)\n",
      "(32, 2, 128, 128, 3)\n",
      "(38, 2, 128, 128, 3)\n",
      "(76, 2, 128, 128, 3)\n",
      "(39, 2, 128, 128, 3)\n",
      "(36, 2, 128, 128, 3)\n",
      "(45, 2, 128, 128, 3)\n",
      "(29, 2, 128, 128, 3)\n",
      "(26, 2, 128, 128, 3)\n",
      "(22, 2, 128, 128, 3)\n",
      "(40, 2, 128, 128, 3)\n",
      "(29, 2, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# find trajectory length for each trajectory in dataset\n",
    "# traj_lengths = []\n",
    "# for traj in dataset:\n",
    "#     print(traj['obs']['camera/image/varied_camera_1_left_image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [24, 2, 128, 128, 3] at entry 0 and [23, 2, 128, 128, 3] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m pytorch_dataset \u001b[38;5;241m=\u001b[39m TorchRLDSDataset(dataset)\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      3\u001b[0m     pytorch_dataset,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      5\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# important to keep this to 0 so PyTorch does not mess with the parallelism\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader)):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5000\u001b[39m:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\willi\\.conda\\envs\\octo\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [24, 2, 128, 128, 3] at entry 0 and [23, 2, 128, 128, 3] at entry 1"
     ]
    }
   ],
   "source": [
    "pytorch_dataset = TorchRLDSDataset(dataset)\n",
    "train_loader = DataLoader(\n",
    "    pytorch_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=0,  # important to keep this to 0 so PyTorch does not mess with the parallelism\n",
    ")\n",
    "\n",
    "for i, sample in tqdm.tqdm(enumerate(train_loader)):\n",
    "    if i == 5000:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
